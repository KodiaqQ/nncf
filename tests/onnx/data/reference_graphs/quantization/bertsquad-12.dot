strict digraph  {
"0 unique_ids_graph_outputs_Identity__10" [id=0, type=Identity];
"1 bert/encoder/ones/packed_Unsqueeze__20" [id=1, type=Unsqueeze];
"2 bert/encoder/ones/packed_Unsqueeze__19" [id=2, type=Unsqueeze];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [id=3, type=Unsqueeze];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [id=4, type=Unsqueeze];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [id=5, type=Unsqueeze];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [id=6, type=Unsqueeze];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [id=7, type=Unsqueeze];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [id=8, type=Unsqueeze];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [id=9, type=Unsqueeze];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [id=10, type=Unsqueeze];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [id=11, type=Unsqueeze];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [id=12, type=Unsqueeze];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [id=13, type=Unsqueeze];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [id=14, type=Unsqueeze];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [id=15, type=Unsqueeze];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [id=16, type=Unsqueeze];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [id=17, type=Unsqueeze];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [id=18, type=Unsqueeze];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [id=19, type=Unsqueeze];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [id=20, type=Unsqueeze];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [id=21, type=Unsqueeze];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [id=22, type=Unsqueeze];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [id=23, type=Unsqueeze];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [id=24, type=Unsqueeze];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [id=25, type=Unsqueeze];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [id=26, type=Unsqueeze];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [id=27, type=Unsqueeze];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [id=28, type=Unsqueeze];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [id=29, type=Unsqueeze];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [id=30, type=Unsqueeze];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [id=31, type=Unsqueeze];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [id=32, type=Unsqueeze];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [id=33, type=Unsqueeze];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [id=34, type=Unsqueeze];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [id=35, type=Unsqueeze];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [id=36, type=Unsqueeze];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [id=37, type=Unsqueeze];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [id=38, type=Unsqueeze];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [id=39, type=Unsqueeze];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [id=40, type=Unsqueeze];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [id=41, type=Unsqueeze];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [id=42, type=Unsqueeze];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [id=43, type=Unsqueeze];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [id=44, type=Unsqueeze];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [id=45, type=Unsqueeze];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [id=46, type=Unsqueeze];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [id=47, type=Unsqueeze];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [id=48, type=Unsqueeze];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [id=49, type=Unsqueeze];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [id=50, type=Unsqueeze];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [id=51, type=Unsqueeze];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [id=52, type=Unsqueeze];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [id=53, type=Unsqueeze];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [id=54, type=Unsqueeze];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [id=55, type=Unsqueeze];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [id=56, type=Unsqueeze];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [id=57, type=Unsqueeze];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [id=58, type=Unsqueeze];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [id=59, type=Unsqueeze];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [id=60, type=Unsqueeze];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [id=61, type=Unsqueeze];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [id=62, type=Unsqueeze];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [id=63, type=Unsqueeze];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [id=64, type=Unsqueeze];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [id=65, type=Unsqueeze];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [id=66, type=Unsqueeze];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [id=67, type=Unsqueeze];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [id=68, type=Unsqueeze];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [id=69, type=Unsqueeze];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [id=70, type=Unsqueeze];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [id=71, type=Unsqueeze];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [id=72, type=Unsqueeze];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [id=73, type=Unsqueeze];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [id=74, type=Unsqueeze];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [id=75, type=Unsqueeze];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [id=76, type=Unsqueeze];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [id=77, type=Unsqueeze];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [id=78, type=Unsqueeze];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [id=79, type=Unsqueeze];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [id=80, type=Unsqueeze];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [id=81, type=Unsqueeze];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [id=82, type=Unsqueeze];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [id=83, type=Unsqueeze];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [id=84, type=Unsqueeze];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [id=85, type=Unsqueeze];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [id=86, type=Unsqueeze];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [id=87, type=Unsqueeze];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [id=88, type=Unsqueeze];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [id=89, type=Unsqueeze];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [id=90, type=Unsqueeze];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [id=91, type=Unsqueeze];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [id=92, type=Unsqueeze];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [id=93, type=Unsqueeze];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [id=94, type=Unsqueeze];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [id=95, type=Unsqueeze];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [id=96, type=Unsqueeze];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [id=97, type=Unsqueeze];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [id=98, type=Unsqueeze];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [id=99, type=Unsqueeze];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [id=100, type=Unsqueeze];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [id=101, type=Unsqueeze];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [id=102, type=Unsqueeze];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [id=103, type=Unsqueeze];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [id=104, type=Unsqueeze];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [id=105, type=Unsqueeze];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [id=106, type=Unsqueeze];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [id=107, type=Unsqueeze];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [id=108, type=Unsqueeze];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [id=109, type=Unsqueeze];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [id=110, type=Unsqueeze];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [id=111, type=Unsqueeze];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [id=112, type=Unsqueeze];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [id=113, type=Unsqueeze];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [id=114, type=Unsqueeze];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [id=115, type=Unsqueeze];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [id=116, type=Unsqueeze];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [id=117, type=Unsqueeze];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [id=118, type=Unsqueeze];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [id=119, type=Unsqueeze];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [id=120, type=Unsqueeze];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [id=121, type=Unsqueeze];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [id=122, type=Unsqueeze];
"123 bert/encoder/Shape" [id=123, type=Shape];
"124 bert/encoder/Shape__12" [id=124, type=Cast];
"125 bert/encoder/strided_slice" [id=125, type=Slice];
"126 bert/encoder/strided_slice__16" [id=126, type=Squeeze];
"127 bert/encoder/strided_slice__17" [id=127, type=Cast];
"128 bert/encoder/ones/packed_Unsqueeze__18" [id=128, type=Unsqueeze];
"129 bert/encoder/ones/packed_Concat__21" [id=129, type=Concat];
"130 bert/encoder/ones__22" [id=130, type=Cast];
"131 bert/encoder/ones" [id=131, type=ConstantOfShape];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" [id=132, type=Unsqueeze];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" [id=133, type=Unsqueeze];
"134 bert/encoder/Reshape_1__302" [id=134, type=Cast];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" [id=135, type=Unsqueeze];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" [id=136, type=Unsqueeze];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" [id=137, type=Unsqueeze];
"138 bert/encoder/Reshape/shape_Concat__26" [id=138, type=Concat];
"139 bert/encoder/Reshape__27" [id=139, type=Cast];
"140 bert/encoder/Reshape" [id=140, type=Reshape];
"141 bert/encoder/Cast" [id=141, type=Cast];
"142 bert/encoder/mul" [id=142, type=Mul];
"143 bert/encoder/layer_9/attention/self/ExpandDims" [id=143, type=Reshape];
"144 bert/encoder/layer_9/attention/self/sub" [id=144, type=Sub];
"145 bert/encoder/layer_9/attention/self/mul_1" [id=145, type=Mul];
"146 bert/encoder/layer_8/attention/self/ExpandDims" [id=146, type=Reshape];
"147 bert/encoder/layer_8/attention/self/sub" [id=147, type=Sub];
"148 bert/encoder/layer_8/attention/self/mul_1" [id=148, type=Mul];
"149 bert/encoder/layer_7/attention/self/ExpandDims" [id=149, type=Reshape];
"150 bert/encoder/layer_7/attention/self/sub" [id=150, type=Sub];
"151 bert/encoder/layer_7/attention/self/mul_1" [id=151, type=Mul];
"152 bert/encoder/layer_6/attention/self/ExpandDims" [id=152, type=Reshape];
"153 bert/encoder/layer_6/attention/self/sub" [id=153, type=Sub];
"154 bert/encoder/layer_6/attention/self/mul_1" [id=154, type=Mul];
"155 bert/encoder/layer_5/attention/self/ExpandDims" [id=155, type=Reshape];
"156 bert/encoder/layer_5/attention/self/sub" [id=156, type=Sub];
"157 bert/encoder/layer_5/attention/self/mul_1" [id=157, type=Mul];
"158 bert/encoder/layer_4/attention/self/ExpandDims" [id=158, type=Reshape];
"159 bert/encoder/layer_4/attention/self/sub" [id=159, type=Sub];
"160 bert/encoder/layer_4/attention/self/mul_1" [id=160, type=Mul];
"161 bert/encoder/layer_3/attention/self/ExpandDims" [id=161, type=Reshape];
"162 bert/encoder/layer_3/attention/self/sub" [id=162, type=Sub];
"163 bert/encoder/layer_3/attention/self/mul_1" [id=163, type=Mul];
"164 bert/encoder/layer_2/attention/self/ExpandDims" [id=164, type=Reshape];
"165 bert/encoder/layer_2/attention/self/sub" [id=165, type=Sub];
"166 bert/encoder/layer_2/attention/self/mul_1" [id=166, type=Mul];
"167 bert/encoder/layer_11/attention/self/ExpandDims" [id=167, type=Reshape];
"168 bert/encoder/layer_11/attention/self/sub" [id=168, type=Sub];
"169 bert/encoder/layer_11/attention/self/mul_1" [id=169, type=Mul];
"170 bert/encoder/layer_10/attention/self/ExpandDims" [id=170, type=Reshape];
"171 bert/encoder/layer_10/attention/self/sub" [id=171, type=Sub];
"172 bert/encoder/layer_10/attention/self/mul_1" [id=172, type=Mul];
"173 bert/encoder/layer_1/attention/self/ExpandDims" [id=173, type=Reshape];
"174 bert/encoder/layer_1/attention/self/sub" [id=174, type=Sub];
"175 bert/encoder/layer_1/attention/self/mul_1" [id=175, type=Mul];
"176 bert/encoder/layer_0/attention/self/ExpandDims" [id=176, type=Reshape];
"177 bert/encoder/layer_0/attention/self/sub" [id=177, type=Sub];
"178 bert/encoder/layer_0/attention/self/mul_1" [id=178, type=Mul];
"179 bert/embeddings/Slice" [id=179, type=Slice];
"180 bert/embeddings/Reshape_4__42" [id=180, type=Cast];
"181 bert/embeddings/Reshape_4" [id=181, type=Reshape];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [id=182, type=Unsqueeze];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [id=183, type=Unsqueeze];
"184 bert/embeddings/Reshape_2__43" [id=184, type=Cast];
"185 bert/embeddings/Reshape_2" [id=185, type=Reshape];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [id=186, type=Unsqueeze];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [id=187, type=Unsqueeze];
"188 bert/embeddings/Reshape__59" [id=188, type=Cast];
"189 bert/embeddings/ExpandDims" [id=189, type=Reshape];
"190 bert/embeddings/Shape" [id=190, type=Shape];
"191 bert/embeddings/Shape__49" [id=191, type=Cast];
"192 bert/embeddings/strided_slice" [id=192, type=Slice];
"193 bert/embeddings/strided_slice__53" [id=193, type=Squeeze];
"194 bert/embeddings/strided_slice__54" [id=194, type=Cast];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [id=195, type=Unsqueeze];
"196 bert/embeddings/Reshape_1/shape_Concat__58" [id=196, type=Concat];
"197 bert/embeddings/Reshape_1__60" [id=197, type=Cast];
"198 bert/embeddings/Reshape" [id=198, type=Reshape];
"199 QuantizeLinear_bert/embeddings/word_embeddings^0_1" [id=199, label="199 QuantizeLinear_bert/embeddings/word_embeddings:0_1", type=QuantizeLinear];
"200 DequantizeLinear_bert/embeddings/word_embeddings^0_1" [id=200, label="200 DequantizeLinear_bert/embeddings/word_embeddings:0_1", type=DequantizeLinear];
"201 bert/embeddings/GatherV2" [id=201, type=Gather];
"202 bert/embeddings/Reshape_1" [id=202, type=Reshape];
"203 bert/embeddings/Shape_1" [id=203, type=Shape];
"204 bert/embeddings/Shape_1__61" [id=204, type=Cast];
"205 bert/embeddings/strided_slice_1" [id=205, type=Slice];
"206 bert/embeddings/strided_slice_1__65" [id=206, type=Squeeze];
"207 bert/embeddings/strided_slice_1__66" [id=207, type=Cast];
"208 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [id=208, type=Unsqueeze];
"209 bert/embeddings/Reshape_3/shape_Concat__70" [id=209, type=Concat];
"210 bert/embeddings/Reshape_3__71" [id=210, type=Cast];
"211 Unsqueeze__46" [id=211, type=Unsqueeze];
"212 Unsqueeze__45" [id=212, type=Unsqueeze];
"213 Unsqueeze__44" [id=213, type=Unsqueeze];
"214 Reshape_1/shape_Unsqueeze__480" [id=214, type=Unsqueeze];
"215 Reshape_1/shape_Unsqueeze__479" [id=215, type=Unsqueeze];
"216 Reshape/shape_Unsqueeze__483" [id=216, type=Unsqueeze];
"217 MatMul__486" [id=217, type=Transpose];
"218 Concat__47" [id=218, type=Concat];
"219 bert/embeddings/one_hot" [id=219, type=OneHot];
"220 QuantizeLinear_bert/embeddings/one_hot^0_1" [id=220, label="220 QuantizeLinear_bert/embeddings/one_hot:0_1", type=QuantizeLinear];
"221 DequantizeLinear_bert/embeddings/one_hot^0_1" [id=221, label="221 DequantizeLinear_bert/embeddings/one_hot:0_1", type=DequantizeLinear];
"222 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=222, label="222 QuantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=QuantizeLinear];
"223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=223, label="223 DequantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=DequantizeLinear];
"224 bert/embeddings/MatMul" [id=224, type=MatMul];
"225 bert/embeddings/Reshape_3" [id=225, type=Reshape];
"226 bert/embeddings/add" [id=226, type=Add];
"227 bert/embeddings/add_1" [id=227, type=Add];
"228 bert/embeddings/LayerNorm/moments/mean" [id=228, type=ReduceMean];
"229 bert/embeddings/LayerNorm/moments/StopGradient" [id=229, type=Identity];
"230 bert/embeddings/LayerNorm/moments/SquaredDifference" [id=230, type=Sub];
"231 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [id=231, type=Mul];
"232 bert/embeddings/LayerNorm/moments/variance" [id=232, type=ReduceMean];
"233 bert/embeddings/LayerNorm/batchnorm/add" [id=233, type=Add];
"234 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [id=234, type=Sqrt];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [id=235, type=Reciprocal];
"236 bert/embeddings/LayerNorm/batchnorm/mul" [id=236, type=Mul];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" [id=237, type=Mul];
"238 bert/embeddings/LayerNorm/batchnorm/sub" [id=238, type=Sub];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" [id=239, type=Mul];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" [id=240, type=Add];
"241 bert/encoder/Shape_2" [id=241, type=Shape];
"242 bert/encoder/Shape_2__76" [id=242, type=Cast];
"243 bert/encoder/strided_slice_2" [id=243, type=Slice];
"244 bert/encoder/strided_slice_2__80" [id=244, type=Squeeze];
"245 bert/encoder/strided_slice_2__81" [id=245, type=Cast];
"246 bert/encoder/layer_9/attention/self/mul_2" [id=246, type=Mul];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [id=247, type=Unsqueeze];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [id=248, type=Concat];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" [id=249, type=Cast];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [id=250, type=Unsqueeze];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [id=251, type=Concat];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" [id=252, type=Cast];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [id=253, type=Unsqueeze];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [id=254, type=Concat];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" [id=255, type=Cast];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [id=256, type=Unsqueeze];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [id=257, type=Concat];
"258 bert/encoder/layer_9/attention/self/Reshape__430" [id=258, type=Cast];
"259 bert/encoder/layer_8/attention/self/mul_2" [id=259, type=Mul];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [id=260, type=Unsqueeze];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [id=261, type=Concat];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" [id=262, type=Cast];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [id=263, type=Unsqueeze];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [id=264, type=Concat];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" [id=265, type=Cast];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [id=266, type=Unsqueeze];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [id=267, type=Concat];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" [id=268, type=Cast];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [id=269, type=Unsqueeze];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [id=270, type=Concat];
"271 bert/encoder/layer_8/attention/self/Reshape__416" [id=271, type=Cast];
"272 bert/encoder/layer_7/attention/self/mul_2" [id=272, type=Mul];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [id=273, type=Unsqueeze];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [id=274, type=Concat];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" [id=275, type=Cast];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [id=276, type=Unsqueeze];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [id=277, type=Concat];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" [id=278, type=Cast];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [id=279, type=Unsqueeze];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [id=280, type=Concat];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" [id=281, type=Cast];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [id=282, type=Unsqueeze];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [id=283, type=Concat];
"284 bert/encoder/layer_7/attention/self/Reshape__402" [id=284, type=Cast];
"285 bert/encoder/layer_6/attention/self/mul_2" [id=285, type=Mul];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [id=286, type=Unsqueeze];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [id=287, type=Concat];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" [id=288, type=Cast];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [id=289, type=Unsqueeze];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [id=290, type=Concat];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" [id=291, type=Cast];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [id=292, type=Unsqueeze];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [id=293, type=Concat];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" [id=294, type=Cast];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [id=295, type=Unsqueeze];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [id=296, type=Concat];
"297 bert/encoder/layer_6/attention/self/Reshape__388" [id=297, type=Cast];
"298 bert/encoder/layer_5/attention/self/mul_2" [id=298, type=Mul];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [id=299, type=Unsqueeze];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [id=300, type=Concat];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" [id=301, type=Cast];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [id=302, type=Unsqueeze];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [id=303, type=Concat];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" [id=304, type=Cast];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [id=305, type=Unsqueeze];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [id=306, type=Concat];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" [id=307, type=Cast];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [id=308, type=Unsqueeze];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [id=309, type=Concat];
"310 bert/encoder/layer_5/attention/self/Reshape__374" [id=310, type=Cast];
"311 bert/encoder/layer_4/attention/self/mul_2" [id=311, type=Mul];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [id=312, type=Unsqueeze];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [id=313, type=Concat];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" [id=314, type=Cast];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [id=315, type=Unsqueeze];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [id=316, type=Concat];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" [id=317, type=Cast];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [id=318, type=Unsqueeze];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [id=319, type=Concat];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" [id=320, type=Cast];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [id=321, type=Unsqueeze];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [id=322, type=Concat];
"323 bert/encoder/layer_4/attention/self/Reshape__360" [id=323, type=Cast];
"324 bert/encoder/layer_3/attention/self/mul_2" [id=324, type=Mul];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [id=325, type=Unsqueeze];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [id=326, type=Concat];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" [id=327, type=Cast];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [id=328, type=Unsqueeze];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [id=329, type=Concat];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" [id=330, type=Cast];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [id=331, type=Unsqueeze];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [id=332, type=Concat];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" [id=333, type=Cast];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [id=334, type=Unsqueeze];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [id=335, type=Concat];
"336 bert/encoder/layer_3/attention/self/Reshape__346" [id=336, type=Cast];
"337 bert/encoder/layer_2/attention/self/mul_2" [id=337, type=Mul];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [id=338, type=Unsqueeze];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [id=339, type=Concat];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" [id=340, type=Cast];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [id=341, type=Unsqueeze];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [id=342, type=Concat];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" [id=343, type=Cast];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [id=344, type=Unsqueeze];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [id=345, type=Concat];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" [id=346, type=Cast];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [id=347, type=Unsqueeze];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [id=348, type=Concat];
"349 bert/encoder/layer_2/attention/self/Reshape__332" [id=349, type=Cast];
"350 bert/encoder/layer_11/attention/self/mul_2" [id=350, type=Mul];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [id=351, type=Unsqueeze];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [id=352, type=Concat];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" [id=353, type=Cast];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [id=354, type=Unsqueeze];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [id=355, type=Concat];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" [id=356, type=Cast];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [id=357, type=Unsqueeze];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [id=358, type=Concat];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" [id=359, type=Cast];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [id=360, type=Unsqueeze];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [id=361, type=Concat];
"362 bert/encoder/layer_11/attention/self/Reshape__458" [id=362, type=Cast];
"363 bert/encoder/layer_10/attention/self/mul_2" [id=363, type=Mul];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [id=364, type=Unsqueeze];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [id=365, type=Concat];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" [id=366, type=Cast];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [id=367, type=Unsqueeze];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [id=368, type=Concat];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" [id=369, type=Cast];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [id=370, type=Unsqueeze];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [id=371, type=Concat];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" [id=372, type=Cast];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [id=373, type=Unsqueeze];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [id=374, type=Concat];
"375 bert/encoder/layer_10/attention/self/Reshape__444" [id=375, type=Cast];
"376 bert/encoder/layer_1/attention/self/mul_2" [id=376, type=Mul];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [id=377, type=Unsqueeze];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [id=378, type=Concat];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" [id=379, type=Cast];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [id=380, type=Unsqueeze];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [id=381, type=Concat];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" [id=382, type=Cast];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [id=383, type=Unsqueeze];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [id=384, type=Concat];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" [id=385, type=Cast];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [id=386, type=Unsqueeze];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [id=387, type=Concat];
"388 bert/encoder/layer_1/attention/self/Reshape__318" [id=388, type=Cast];
"389 bert/encoder/layer_0/attention/self/mul_2" [id=389, type=Mul];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [id=390, type=Unsqueeze];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [id=391, type=Concat];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" [id=392, type=Cast];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [id=393, type=Unsqueeze];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [id=394, type=Concat];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" [id=395, type=Cast];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [id=396, type=Unsqueeze];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [id=397, type=Concat];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" [id=398, type=Cast];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [id=399, type=Unsqueeze];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [id=400, type=Concat];
"401 bert/encoder/layer_0/attention/self/Reshape__304" [id=401, type=Cast];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" [id=402, type=Unsqueeze];
"403 bert/encoder/Reshape_13/shape_Concat__301" [id=403, type=Concat];
"404 bert/encoder/Reshape_13__471" [id=404, type=Cast];
"405 bert/encoder/Reshape_1" [id=405, type=Reshape];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_1" [id=406, label="406 QuantizeLinear_bert/encoder/Reshape_1:0_1", type=QuantizeLinear];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" [id=407, label="407 DequantizeLinear_bert/encoder/Reshape_1:0_1", type=DequantizeLinear];
"408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=408, label="408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=QuantizeLinear];
"409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=409, label="409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=DequantizeLinear];
"410 bert/encoder/layer_0/attention/self/value/MatMul" [id=410, type=MatMul];
"411 bert/encoder/layer_0/attention/self/value/BiasAdd" [id=411, type=Add];
"412 bert/encoder/layer_0/attention/self/Reshape_2" [id=412, type=Reshape];
"413 bert/encoder/layer_0/attention/self/transpose_2" [id=413, type=Transpose];
"414 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=414, label="414 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=QuantizeLinear];
"415 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=415, label="415 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=DequantizeLinear];
"416 bert/encoder/layer_0/attention/self/query/MatMul" [id=416, type=MatMul];
"417 bert/encoder/layer_0/attention/self/query/BiasAdd" [id=417, type=Add];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=418, label="418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=419, label="419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"420 bert/encoder/layer_0/attention/self/Reshape" [id=420, type=Reshape];
"421 bert/encoder/layer_0/attention/self/transpose" [id=421, type=Transpose];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=422, label="422 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=QuantizeLinear];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=423, label="423 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=DequantizeLinear];
"424 bert/encoder/layer_0/attention/self/key/MatMul" [id=424, type=MatMul];
"425 bert/encoder/layer_0/attention/self/key/BiasAdd" [id=425, type=Add];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=426, label="426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=427, label="427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"428 bert/encoder/layer_0/attention/self/Reshape_1" [id=428, type=Reshape];
"429 bert/encoder/layer_0/attention/self/transpose_1" [id=429, type=Transpose];
"430 bert/encoder/layer_0/attention/self/MatMul__306" [id=430, type=Transpose];
"431 bert/encoder/layer_0/attention/self/MatMul" [id=431, type=MatMul];
"432 bert/encoder/layer_0/attention/self/Mul" [id=432, type=Mul];
"433 bert/encoder/layer_0/attention/self/add" [id=433, type=Add];
"434 bert/encoder/layer_0/attention/self/Softmax" [id=434, type=Softmax];
"435 bert/encoder/layer_0/attention/self/MatMul_1" [id=435, type=MatMul];
"436 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=436, label="436 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"437 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=437, label="437 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"438 bert/encoder/layer_0/attention/self/transpose_3" [id=438, type=Transpose];
"439 bert/encoder/layer_0/attention/self/Reshape_3" [id=439, type=Reshape];
"440 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=440, label="440 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"441 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=441, label="441 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"442 bert/encoder/layer_0/attention/output/dense/MatMul" [id=442, type=MatMul];
"443 bert/encoder/layer_0/attention/output/dense/BiasAdd" [id=443, type=Add];
"444 bert/encoder/layer_0/attention/output/add" [id=444, type=Add];
"445 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [id=445, type=ReduceMean];
"446 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [id=446, type=Identity];
"447 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [id=447, type=Sub];
"448 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [id=448, type=Mul];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [id=449, type=ReduceMean];
"450 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [id=450, type=Add];
"451 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [id=451, type=Sqrt];
"452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [id=452, type=Reciprocal];
"453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [id=453, type=Mul];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [id=454, type=Mul];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [id=455, type=Sub];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [id=456, type=Mul];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [id=457, type=Add];
"458 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=458, label="458 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"459 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=459, label="459 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"460 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=460, label="460 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"461 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=461, label="461 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"462 bert/encoder/layer_0/intermediate/dense/MatMul" [id=462, type=MatMul];
"463 bert/encoder/layer_0/intermediate/dense/BiasAdd" [id=463, type=Add];
"464 bert/encoder/layer_0/intermediate/dense/Pow" [id=464, type=Pow];
"465 bert/encoder/layer_0/intermediate/dense/mul" [id=465, type=Mul];
"466 bert/encoder/layer_0/intermediate/dense/add" [id=466, type=Add];
"467 bert/encoder/layer_0/intermediate/dense/mul_1" [id=467, type=Mul];
"468 bert/encoder/layer_0/intermediate/dense/Tanh" [id=468, type=Tanh];
"469 bert/encoder/layer_0/intermediate/dense/add_1" [id=469, type=Add];
"470 bert/encoder/layer_0/intermediate/dense/mul_2" [id=470, type=Mul];
"471 bert/encoder/layer_0/intermediate/dense/mul_3" [id=471, type=Mul];
"472 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=472, label="472 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"473 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=473, label="473 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"474 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=474, label="474 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=QuantizeLinear];
"475 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=475, label="475 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=DequantizeLinear];
"476 bert/encoder/layer_0/output/dense/MatMul" [id=476, type=MatMul];
"477 bert/encoder/layer_0/output/dense/BiasAdd" [id=477, type=Add];
"478 bert/encoder/layer_0/output/add" [id=478, type=Add];
"479 bert/encoder/layer_0/output/LayerNorm/moments/mean" [id=479, type=ReduceMean];
"480 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [id=480, type=Identity];
"481 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [id=481, type=Sub];
"482 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [id=482, type=Mul];
"483 bert/encoder/layer_0/output/LayerNorm/moments/variance" [id=483, type=ReduceMean];
"484 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [id=484, type=Add];
"485 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [id=485, type=Sqrt];
"486 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [id=486, type=Reciprocal];
"487 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [id=487, type=Mul];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [id=488, type=Mul];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [id=489, type=Sub];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [id=490, type=Mul];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [id=491, type=Add];
"492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=492, label="492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=493, label="493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=494, label="494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=495, label="495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=496, label="496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=497, label="497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=498, label="498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=QuantizeLinear];
"499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=499, label="499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=DequantizeLinear];
"500 bert/encoder/layer_1/attention/self/value/MatMul" [id=500, type=MatMul];
"501 bert/encoder/layer_1/attention/self/value/BiasAdd" [id=501, type=Add];
"502 bert/encoder/layer_1/attention/self/Reshape_2" [id=502, type=Reshape];
"503 bert/encoder/layer_1/attention/self/transpose_2" [id=503, type=Transpose];
"504 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=504, label="504 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=QuantizeLinear];
"505 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=505, label="505 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=DequantizeLinear];
"506 bert/encoder/layer_1/attention/self/query/MatMul" [id=506, type=MatMul];
"507 bert/encoder/layer_1/attention/self/query/BiasAdd" [id=507, type=Add];
"508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=508, label="508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=509, label="509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"510 bert/encoder/layer_1/attention/self/Reshape" [id=510, type=Reshape];
"511 bert/encoder/layer_1/attention/self/transpose" [id=511, type=Transpose];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=512, label="512 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=QuantizeLinear];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=513, label="513 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=DequantizeLinear];
"514 bert/encoder/layer_1/attention/self/key/MatMul" [id=514, type=MatMul];
"515 bert/encoder/layer_1/attention/self/key/BiasAdd" [id=515, type=Add];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=516, label="516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=517, label="517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"518 bert/encoder/layer_1/attention/self/Reshape_1" [id=518, type=Reshape];
"519 bert/encoder/layer_1/attention/self/transpose_1" [id=519, type=Transpose];
"520 bert/encoder/layer_1/attention/self/MatMul__320" [id=520, type=Transpose];
"521 bert/encoder/layer_1/attention/self/MatMul" [id=521, type=MatMul];
"522 bert/encoder/layer_1/attention/self/Mul" [id=522, type=Mul];
"523 bert/encoder/layer_1/attention/self/add" [id=523, type=Add];
"524 bert/encoder/layer_1/attention/self/Softmax" [id=524, type=Softmax];
"525 bert/encoder/layer_1/attention/self/MatMul_1" [id=525, type=MatMul];
"526 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=526, label="526 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"527 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=527, label="527 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"528 bert/encoder/layer_1/attention/self/transpose_3" [id=528, type=Transpose];
"529 bert/encoder/layer_1/attention/self/Reshape_3" [id=529, type=Reshape];
"530 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=530, label="530 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"531 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=531, label="531 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"532 bert/encoder/layer_1/attention/output/dense/MatMul" [id=532, type=MatMul];
"533 bert/encoder/layer_1/attention/output/dense/BiasAdd" [id=533, type=Add];
"534 bert/encoder/layer_1/attention/output/add" [id=534, type=Add];
"535 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [id=535, type=ReduceMean];
"536 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [id=536, type=Identity];
"537 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [id=537, type=Sub];
"538 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [id=538, type=Mul];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [id=539, type=ReduceMean];
"540 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [id=540, type=Add];
"541 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [id=541, type=Sqrt];
"542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [id=542, type=Reciprocal];
"543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [id=543, type=Mul];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [id=544, type=Mul];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [id=545, type=Sub];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [id=546, type=Mul];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [id=547, type=Add];
"548 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=548, label="548 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"549 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=549, label="549 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"550 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=550, label="550 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"551 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=551, label="551 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"552 bert/encoder/layer_1/intermediate/dense/MatMul" [id=552, type=MatMul];
"553 bert/encoder/layer_1/intermediate/dense/BiasAdd" [id=553, type=Add];
"554 bert/encoder/layer_1/intermediate/dense/Pow" [id=554, type=Pow];
"555 bert/encoder/layer_1/intermediate/dense/mul" [id=555, type=Mul];
"556 bert/encoder/layer_1/intermediate/dense/add" [id=556, type=Add];
"557 bert/encoder/layer_1/intermediate/dense/mul_1" [id=557, type=Mul];
"558 bert/encoder/layer_1/intermediate/dense/Tanh" [id=558, type=Tanh];
"559 bert/encoder/layer_1/intermediate/dense/add_1" [id=559, type=Add];
"560 bert/encoder/layer_1/intermediate/dense/mul_2" [id=560, type=Mul];
"561 bert/encoder/layer_1/intermediate/dense/mul_3" [id=561, type=Mul];
"562 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=562, label="562 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"563 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=563, label="563 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"564 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=564, label="564 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=QuantizeLinear];
"565 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=565, label="565 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=DequantizeLinear];
"566 bert/encoder/layer_1/output/dense/MatMul" [id=566, type=MatMul];
"567 bert/encoder/layer_1/output/dense/BiasAdd" [id=567, type=Add];
"568 bert/encoder/layer_1/output/add" [id=568, type=Add];
"569 bert/encoder/layer_1/output/LayerNorm/moments/mean" [id=569, type=ReduceMean];
"570 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [id=570, type=Identity];
"571 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [id=571, type=Sub];
"572 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [id=572, type=Mul];
"573 bert/encoder/layer_1/output/LayerNorm/moments/variance" [id=573, type=ReduceMean];
"574 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [id=574, type=Add];
"575 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [id=575, type=Sqrt];
"576 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [id=576, type=Reciprocal];
"577 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [id=577, type=Mul];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [id=578, type=Mul];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [id=579, type=Sub];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [id=580, type=Mul];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [id=581, type=Add];
"582 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=582, label="582 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"583 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=583, label="583 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=584, label="584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=585, label="585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=586, label="586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=587, label="587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=588, label="588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=QuantizeLinear];
"589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=589, label="589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=DequantizeLinear];
"590 bert/encoder/layer_2/attention/self/value/MatMul" [id=590, type=MatMul];
"591 bert/encoder/layer_2/attention/self/value/BiasAdd" [id=591, type=Add];
"592 bert/encoder/layer_2/attention/self/Reshape_2" [id=592, type=Reshape];
"593 bert/encoder/layer_2/attention/self/transpose_2" [id=593, type=Transpose];
"594 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=594, label="594 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=QuantizeLinear];
"595 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=595, label="595 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=DequantizeLinear];
"596 bert/encoder/layer_2/attention/self/query/MatMul" [id=596, type=MatMul];
"597 bert/encoder/layer_2/attention/self/query/BiasAdd" [id=597, type=Add];
"598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=598, label="598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=599, label="599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"600 bert/encoder/layer_2/attention/self/Reshape" [id=600, type=Reshape];
"601 bert/encoder/layer_2/attention/self/transpose" [id=601, type=Transpose];
"602 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=602, label="602 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=QuantizeLinear];
"603 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=603, label="603 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=DequantizeLinear];
"604 bert/encoder/layer_2/attention/self/key/MatMul" [id=604, type=MatMul];
"605 bert/encoder/layer_2/attention/self/key/BiasAdd" [id=605, type=Add];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=606, label="606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=607, label="607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"608 bert/encoder/layer_2/attention/self/Reshape_1" [id=608, type=Reshape];
"609 bert/encoder/layer_2/attention/self/transpose_1" [id=609, type=Transpose];
"610 bert/encoder/layer_2/attention/self/MatMul__334" [id=610, type=Transpose];
"611 bert/encoder/layer_2/attention/self/MatMul" [id=611, type=MatMul];
"612 bert/encoder/layer_2/attention/self/Mul" [id=612, type=Mul];
"613 bert/encoder/layer_2/attention/self/add" [id=613, type=Add];
"614 bert/encoder/layer_2/attention/self/Softmax" [id=614, type=Softmax];
"615 bert/encoder/layer_2/attention/self/MatMul_1" [id=615, type=MatMul];
"616 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=616, label="616 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"617 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=617, label="617 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"618 bert/encoder/layer_2/attention/self/transpose_3" [id=618, type=Transpose];
"619 bert/encoder/layer_2/attention/self/Reshape_3" [id=619, type=Reshape];
"620 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=620, label="620 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"621 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=621, label="621 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"622 bert/encoder/layer_2/attention/output/dense/MatMul" [id=622, type=MatMul];
"623 bert/encoder/layer_2/attention/output/dense/BiasAdd" [id=623, type=Add];
"624 bert/encoder/layer_2/attention/output/add" [id=624, type=Add];
"625 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [id=625, type=ReduceMean];
"626 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [id=626, type=Identity];
"627 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [id=627, type=Sub];
"628 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [id=628, type=Mul];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [id=629, type=ReduceMean];
"630 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [id=630, type=Add];
"631 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [id=631, type=Sqrt];
"632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [id=632, type=Reciprocal];
"633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [id=633, type=Mul];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [id=634, type=Mul];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [id=635, type=Sub];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [id=636, type=Mul];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [id=637, type=Add];
"638 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=638, label="638 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"639 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=639, label="639 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"640 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=640, label="640 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"641 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=641, label="641 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"642 bert/encoder/layer_2/intermediate/dense/MatMul" [id=642, type=MatMul];
"643 bert/encoder/layer_2/intermediate/dense/BiasAdd" [id=643, type=Add];
"644 bert/encoder/layer_2/intermediate/dense/Pow" [id=644, type=Pow];
"645 bert/encoder/layer_2/intermediate/dense/mul" [id=645, type=Mul];
"646 bert/encoder/layer_2/intermediate/dense/add" [id=646, type=Add];
"647 bert/encoder/layer_2/intermediate/dense/mul_1" [id=647, type=Mul];
"648 bert/encoder/layer_2/intermediate/dense/Tanh" [id=648, type=Tanh];
"649 bert/encoder/layer_2/intermediate/dense/add_1" [id=649, type=Add];
"650 bert/encoder/layer_2/intermediate/dense/mul_2" [id=650, type=Mul];
"651 bert/encoder/layer_2/intermediate/dense/mul_3" [id=651, type=Mul];
"652 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=652, label="652 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"653 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=653, label="653 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"654 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=654, label="654 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=QuantizeLinear];
"655 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=655, label="655 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=DequantizeLinear];
"656 bert/encoder/layer_2/output/dense/MatMul" [id=656, type=MatMul];
"657 bert/encoder/layer_2/output/dense/BiasAdd" [id=657, type=Add];
"658 bert/encoder/layer_2/output/add" [id=658, type=Add];
"659 bert/encoder/layer_2/output/LayerNorm/moments/mean" [id=659, type=ReduceMean];
"660 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [id=660, type=Identity];
"661 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [id=661, type=Sub];
"662 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [id=662, type=Mul];
"663 bert/encoder/layer_2/output/LayerNorm/moments/variance" [id=663, type=ReduceMean];
"664 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [id=664, type=Add];
"665 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [id=665, type=Sqrt];
"666 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [id=666, type=Reciprocal];
"667 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [id=667, type=Mul];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [id=668, type=Mul];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [id=669, type=Sub];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [id=670, type=Mul];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [id=671, type=Add];
"672 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=672, label="672 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"673 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=673, label="673 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=674, label="674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=675, label="675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=676, label="676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=677, label="677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=678, label="678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=QuantizeLinear];
"679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=679, label="679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=DequantizeLinear];
"680 bert/encoder/layer_3/attention/self/value/MatMul" [id=680, type=MatMul];
"681 bert/encoder/layer_3/attention/self/value/BiasAdd" [id=681, type=Add];
"682 bert/encoder/layer_3/attention/self/Reshape_2" [id=682, type=Reshape];
"683 bert/encoder/layer_3/attention/self/transpose_2" [id=683, type=Transpose];
"684 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=684, label="684 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=QuantizeLinear];
"685 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=685, label="685 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=DequantizeLinear];
"686 bert/encoder/layer_3/attention/self/query/MatMul" [id=686, type=MatMul];
"687 bert/encoder/layer_3/attention/self/query/BiasAdd" [id=687, type=Add];
"688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=688, label="688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=689, label="689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"690 bert/encoder/layer_3/attention/self/Reshape" [id=690, type=Reshape];
"691 bert/encoder/layer_3/attention/self/transpose" [id=691, type=Transpose];
"692 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=692, label="692 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=QuantizeLinear];
"693 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=693, label="693 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=DequantizeLinear];
"694 bert/encoder/layer_3/attention/self/key/MatMul" [id=694, type=MatMul];
"695 bert/encoder/layer_3/attention/self/key/BiasAdd" [id=695, type=Add];
"696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=696, label="696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=697, label="697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"698 bert/encoder/layer_3/attention/self/Reshape_1" [id=698, type=Reshape];
"699 bert/encoder/layer_3/attention/self/transpose_1" [id=699, type=Transpose];
"700 bert/encoder/layer_3/attention/self/MatMul__348" [id=700, type=Transpose];
"701 bert/encoder/layer_3/attention/self/MatMul" [id=701, type=MatMul];
"702 bert/encoder/layer_3/attention/self/Mul" [id=702, type=Mul];
"703 bert/encoder/layer_3/attention/self/add" [id=703, type=Add];
"704 bert/encoder/layer_3/attention/self/Softmax" [id=704, type=Softmax];
"705 bert/encoder/layer_3/attention/self/MatMul_1" [id=705, type=MatMul];
"706 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=706, label="706 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"707 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=707, label="707 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"708 bert/encoder/layer_3/attention/self/transpose_3" [id=708, type=Transpose];
"709 bert/encoder/layer_3/attention/self/Reshape_3" [id=709, type=Reshape];
"710 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=710, label="710 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"711 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=711, label="711 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"712 bert/encoder/layer_3/attention/output/dense/MatMul" [id=712, type=MatMul];
"713 bert/encoder/layer_3/attention/output/dense/BiasAdd" [id=713, type=Add];
"714 bert/encoder/layer_3/attention/output/add" [id=714, type=Add];
"715 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [id=715, type=ReduceMean];
"716 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [id=716, type=Identity];
"717 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [id=717, type=Sub];
"718 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [id=718, type=Mul];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [id=719, type=ReduceMean];
"720 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [id=720, type=Add];
"721 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [id=721, type=Sqrt];
"722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [id=722, type=Reciprocal];
"723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [id=723, type=Mul];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [id=724, type=Mul];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [id=725, type=Sub];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [id=726, type=Mul];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [id=727, type=Add];
"728 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=728, label="728 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"729 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=729, label="729 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"730 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=730, label="730 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"731 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=731, label="731 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"732 bert/encoder/layer_3/intermediate/dense/MatMul" [id=732, type=MatMul];
"733 bert/encoder/layer_3/intermediate/dense/BiasAdd" [id=733, type=Add];
"734 bert/encoder/layer_3/intermediate/dense/Pow" [id=734, type=Pow];
"735 bert/encoder/layer_3/intermediate/dense/mul" [id=735, type=Mul];
"736 bert/encoder/layer_3/intermediate/dense/add" [id=736, type=Add];
"737 bert/encoder/layer_3/intermediate/dense/mul_1" [id=737, type=Mul];
"738 bert/encoder/layer_3/intermediate/dense/Tanh" [id=738, type=Tanh];
"739 bert/encoder/layer_3/intermediate/dense/add_1" [id=739, type=Add];
"740 bert/encoder/layer_3/intermediate/dense/mul_2" [id=740, type=Mul];
"741 bert/encoder/layer_3/intermediate/dense/mul_3" [id=741, type=Mul];
"742 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=742, label="742 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"743 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=743, label="743 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"744 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=744, label="744 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=QuantizeLinear];
"745 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=745, label="745 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=DequantizeLinear];
"746 bert/encoder/layer_3/output/dense/MatMul" [id=746, type=MatMul];
"747 bert/encoder/layer_3/output/dense/BiasAdd" [id=747, type=Add];
"748 bert/encoder/layer_3/output/add" [id=748, type=Add];
"749 bert/encoder/layer_3/output/LayerNorm/moments/mean" [id=749, type=ReduceMean];
"750 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [id=750, type=Identity];
"751 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [id=751, type=Sub];
"752 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [id=752, type=Mul];
"753 bert/encoder/layer_3/output/LayerNorm/moments/variance" [id=753, type=ReduceMean];
"754 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [id=754, type=Add];
"755 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [id=755, type=Sqrt];
"756 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [id=756, type=Reciprocal];
"757 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [id=757, type=Mul];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [id=758, type=Mul];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [id=759, type=Sub];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [id=760, type=Mul];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [id=761, type=Add];
"762 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=762, label="762 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"763 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=763, label="763 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=764, label="764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=765, label="765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=766, label="766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=767, label="767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=768, label="768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=QuantizeLinear];
"769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=769, label="769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=DequantizeLinear];
"770 bert/encoder/layer_4/attention/self/value/MatMul" [id=770, type=MatMul];
"771 bert/encoder/layer_4/attention/self/value/BiasAdd" [id=771, type=Add];
"772 bert/encoder/layer_4/attention/self/Reshape_2" [id=772, type=Reshape];
"773 bert/encoder/layer_4/attention/self/transpose_2" [id=773, type=Transpose];
"774 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=774, label="774 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=QuantizeLinear];
"775 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=775, label="775 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=DequantizeLinear];
"776 bert/encoder/layer_4/attention/self/query/MatMul" [id=776, type=MatMul];
"777 bert/encoder/layer_4/attention/self/query/BiasAdd" [id=777, type=Add];
"778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=778, label="778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=779, label="779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"780 bert/encoder/layer_4/attention/self/Reshape" [id=780, type=Reshape];
"781 bert/encoder/layer_4/attention/self/transpose" [id=781, type=Transpose];
"782 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=782, label="782 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=QuantizeLinear];
"783 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=783, label="783 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=DequantizeLinear];
"784 bert/encoder/layer_4/attention/self/key/MatMul" [id=784, type=MatMul];
"785 bert/encoder/layer_4/attention/self/key/BiasAdd" [id=785, type=Add];
"786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=786, label="786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=787, label="787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"788 bert/encoder/layer_4/attention/self/Reshape_1" [id=788, type=Reshape];
"789 bert/encoder/layer_4/attention/self/transpose_1" [id=789, type=Transpose];
"790 bert/encoder/layer_4/attention/self/MatMul__362" [id=790, type=Transpose];
"791 bert/encoder/layer_4/attention/self/MatMul" [id=791, type=MatMul];
"792 bert/encoder/layer_4/attention/self/Mul" [id=792, type=Mul];
"793 bert/encoder/layer_4/attention/self/add" [id=793, type=Add];
"794 bert/encoder/layer_4/attention/self/Softmax" [id=794, type=Softmax];
"795 bert/encoder/layer_4/attention/self/MatMul_1" [id=795, type=MatMul];
"796 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=796, label="796 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"797 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=797, label="797 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"798 bert/encoder/layer_4/attention/self/transpose_3" [id=798, type=Transpose];
"799 bert/encoder/layer_4/attention/self/Reshape_3" [id=799, type=Reshape];
"800 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=800, label="800 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"801 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=801, label="801 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"802 bert/encoder/layer_4/attention/output/dense/MatMul" [id=802, type=MatMul];
"803 bert/encoder/layer_4/attention/output/dense/BiasAdd" [id=803, type=Add];
"804 bert/encoder/layer_4/attention/output/add" [id=804, type=Add];
"805 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [id=805, type=ReduceMean];
"806 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [id=806, type=Identity];
"807 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [id=807, type=Sub];
"808 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [id=808, type=Mul];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [id=809, type=ReduceMean];
"810 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [id=810, type=Add];
"811 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [id=811, type=Sqrt];
"812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [id=812, type=Reciprocal];
"813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [id=813, type=Mul];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [id=814, type=Mul];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [id=815, type=Sub];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [id=816, type=Mul];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [id=817, type=Add];
"818 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=818, label="818 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"819 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=819, label="819 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"820 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=820, label="820 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"821 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=821, label="821 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"822 bert/encoder/layer_4/intermediate/dense/MatMul" [id=822, type=MatMul];
"823 bert/encoder/layer_4/intermediate/dense/BiasAdd" [id=823, type=Add];
"824 bert/encoder/layer_4/intermediate/dense/Pow" [id=824, type=Pow];
"825 bert/encoder/layer_4/intermediate/dense/mul" [id=825, type=Mul];
"826 bert/encoder/layer_4/intermediate/dense/add" [id=826, type=Add];
"827 bert/encoder/layer_4/intermediate/dense/mul_1" [id=827, type=Mul];
"828 bert/encoder/layer_4/intermediate/dense/Tanh" [id=828, type=Tanh];
"829 bert/encoder/layer_4/intermediate/dense/add_1" [id=829, type=Add];
"830 bert/encoder/layer_4/intermediate/dense/mul_2" [id=830, type=Mul];
"831 bert/encoder/layer_4/intermediate/dense/mul_3" [id=831, type=Mul];
"832 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=832, label="832 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"833 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=833, label="833 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"834 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=834, label="834 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=QuantizeLinear];
"835 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=835, label="835 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=DequantizeLinear];
"836 bert/encoder/layer_4/output/dense/MatMul" [id=836, type=MatMul];
"837 bert/encoder/layer_4/output/dense/BiasAdd" [id=837, type=Add];
"838 bert/encoder/layer_4/output/add" [id=838, type=Add];
"839 bert/encoder/layer_4/output/LayerNorm/moments/mean" [id=839, type=ReduceMean];
"840 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [id=840, type=Identity];
"841 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [id=841, type=Sub];
"842 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [id=842, type=Mul];
"843 bert/encoder/layer_4/output/LayerNorm/moments/variance" [id=843, type=ReduceMean];
"844 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [id=844, type=Add];
"845 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [id=845, type=Sqrt];
"846 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [id=846, type=Reciprocal];
"847 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [id=847, type=Mul];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [id=848, type=Mul];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [id=849, type=Sub];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [id=850, type=Mul];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [id=851, type=Add];
"852 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=852, label="852 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"853 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=853, label="853 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=854, label="854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=855, label="855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=856, label="856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=857, label="857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=858, label="858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=QuantizeLinear];
"859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=859, label="859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=DequantizeLinear];
"860 bert/encoder/layer_5/attention/self/value/MatMul" [id=860, type=MatMul];
"861 bert/encoder/layer_5/attention/self/value/BiasAdd" [id=861, type=Add];
"862 bert/encoder/layer_5/attention/self/Reshape_2" [id=862, type=Reshape];
"863 bert/encoder/layer_5/attention/self/transpose_2" [id=863, type=Transpose];
"864 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=864, label="864 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=QuantizeLinear];
"865 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=865, label="865 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=DequantizeLinear];
"866 bert/encoder/layer_5/attention/self/query/MatMul" [id=866, type=MatMul];
"867 bert/encoder/layer_5/attention/self/query/BiasAdd" [id=867, type=Add];
"868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=868, label="868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=869, label="869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"870 bert/encoder/layer_5/attention/self/Reshape" [id=870, type=Reshape];
"871 bert/encoder/layer_5/attention/self/transpose" [id=871, type=Transpose];
"872 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=872, label="872 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=QuantizeLinear];
"873 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=873, label="873 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=DequantizeLinear];
"874 bert/encoder/layer_5/attention/self/key/MatMul" [id=874, type=MatMul];
"875 bert/encoder/layer_5/attention/self/key/BiasAdd" [id=875, type=Add];
"876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=876, label="876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=877, label="877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"878 bert/encoder/layer_5/attention/self/Reshape_1" [id=878, type=Reshape];
"879 bert/encoder/layer_5/attention/self/transpose_1" [id=879, type=Transpose];
"880 bert/encoder/layer_5/attention/self/MatMul__376" [id=880, type=Transpose];
"881 bert/encoder/layer_5/attention/self/MatMul" [id=881, type=MatMul];
"882 bert/encoder/layer_5/attention/self/Mul" [id=882, type=Mul];
"883 bert/encoder/layer_5/attention/self/add" [id=883, type=Add];
"884 bert/encoder/layer_5/attention/self/Softmax" [id=884, type=Softmax];
"885 bert/encoder/layer_5/attention/self/MatMul_1" [id=885, type=MatMul];
"886 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=886, label="886 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"887 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=887, label="887 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"888 bert/encoder/layer_5/attention/self/transpose_3" [id=888, type=Transpose];
"889 bert/encoder/layer_5/attention/self/Reshape_3" [id=889, type=Reshape];
"890 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=890, label="890 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"891 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=891, label="891 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"892 bert/encoder/layer_5/attention/output/dense/MatMul" [id=892, type=MatMul];
"893 bert/encoder/layer_5/attention/output/dense/BiasAdd" [id=893, type=Add];
"894 bert/encoder/layer_5/attention/output/add" [id=894, type=Add];
"895 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [id=895, type=ReduceMean];
"896 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [id=896, type=Identity];
"897 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [id=897, type=Sub];
"898 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [id=898, type=Mul];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [id=899, type=ReduceMean];
"900 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [id=900, type=Add];
"901 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [id=901, type=Sqrt];
"902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [id=902, type=Reciprocal];
"903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [id=903, type=Mul];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [id=904, type=Mul];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [id=905, type=Sub];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [id=906, type=Mul];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [id=907, type=Add];
"908 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=908, label="908 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"909 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=909, label="909 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"910 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=910, label="910 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"911 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=911, label="911 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"912 bert/encoder/layer_5/intermediate/dense/MatMul" [id=912, type=MatMul];
"913 bert/encoder/layer_5/intermediate/dense/BiasAdd" [id=913, type=Add];
"914 bert/encoder/layer_5/intermediate/dense/Pow" [id=914, type=Pow];
"915 bert/encoder/layer_5/intermediate/dense/mul" [id=915, type=Mul];
"916 bert/encoder/layer_5/intermediate/dense/add" [id=916, type=Add];
"917 bert/encoder/layer_5/intermediate/dense/mul_1" [id=917, type=Mul];
"918 bert/encoder/layer_5/intermediate/dense/Tanh" [id=918, type=Tanh];
"919 bert/encoder/layer_5/intermediate/dense/add_1" [id=919, type=Add];
"920 bert/encoder/layer_5/intermediate/dense/mul_2" [id=920, type=Mul];
"921 bert/encoder/layer_5/intermediate/dense/mul_3" [id=921, type=Mul];
"922 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=922, label="922 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"923 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=923, label="923 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"924 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=924, label="924 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=QuantizeLinear];
"925 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=925, label="925 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=DequantizeLinear];
"926 bert/encoder/layer_5/output/dense/MatMul" [id=926, type=MatMul];
"927 bert/encoder/layer_5/output/dense/BiasAdd" [id=927, type=Add];
"928 bert/encoder/layer_5/output/add" [id=928, type=Add];
"929 bert/encoder/layer_5/output/LayerNorm/moments/mean" [id=929, type=ReduceMean];
"930 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [id=930, type=Identity];
"931 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [id=931, type=Sub];
"932 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [id=932, type=Mul];
"933 bert/encoder/layer_5/output/LayerNorm/moments/variance" [id=933, type=ReduceMean];
"934 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [id=934, type=Add];
"935 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [id=935, type=Sqrt];
"936 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [id=936, type=Reciprocal];
"937 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [id=937, type=Mul];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [id=938, type=Mul];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [id=939, type=Sub];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [id=940, type=Mul];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [id=941, type=Add];
"942 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=942, label="942 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"943 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=943, label="943 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=944, label="944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=945, label="945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=946, label="946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=947, label="947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=948, label="948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=QuantizeLinear];
"949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=949, label="949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=DequantizeLinear];
"950 bert/encoder/layer_6/attention/self/value/MatMul" [id=950, type=MatMul];
"951 bert/encoder/layer_6/attention/self/value/BiasAdd" [id=951, type=Add];
"952 bert/encoder/layer_6/attention/self/Reshape_2" [id=952, type=Reshape];
"953 bert/encoder/layer_6/attention/self/transpose_2" [id=953, type=Transpose];
"954 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=954, label="954 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=QuantizeLinear];
"955 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=955, label="955 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=DequantizeLinear];
"956 bert/encoder/layer_6/attention/self/query/MatMul" [id=956, type=MatMul];
"957 bert/encoder/layer_6/attention/self/query/BiasAdd" [id=957, type=Add];
"958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=958, label="958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=959, label="959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"960 bert/encoder/layer_6/attention/self/Reshape" [id=960, type=Reshape];
"961 bert/encoder/layer_6/attention/self/transpose" [id=961, type=Transpose];
"962 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=962, label="962 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=QuantizeLinear];
"963 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=963, label="963 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=DequantizeLinear];
"964 bert/encoder/layer_6/attention/self/key/MatMul" [id=964, type=MatMul];
"965 bert/encoder/layer_6/attention/self/key/BiasAdd" [id=965, type=Add];
"966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=966, label="966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=967, label="967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"968 bert/encoder/layer_6/attention/self/Reshape_1" [id=968, type=Reshape];
"969 bert/encoder/layer_6/attention/self/transpose_1" [id=969, type=Transpose];
"970 bert/encoder/layer_6/attention/self/MatMul__390" [id=970, type=Transpose];
"971 bert/encoder/layer_6/attention/self/MatMul" [id=971, type=MatMul];
"972 bert/encoder/layer_6/attention/self/Mul" [id=972, type=Mul];
"973 bert/encoder/layer_6/attention/self/add" [id=973, type=Add];
"974 bert/encoder/layer_6/attention/self/Softmax" [id=974, type=Softmax];
"975 bert/encoder/layer_6/attention/self/MatMul_1" [id=975, type=MatMul];
"976 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=976, label="976 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"977 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=977, label="977 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"978 bert/encoder/layer_6/attention/self/transpose_3" [id=978, type=Transpose];
"979 bert/encoder/layer_6/attention/self/Reshape_3" [id=979, type=Reshape];
"980 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=980, label="980 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"981 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=981, label="981 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"982 bert/encoder/layer_6/attention/output/dense/MatMul" [id=982, type=MatMul];
"983 bert/encoder/layer_6/attention/output/dense/BiasAdd" [id=983, type=Add];
"984 bert/encoder/layer_6/attention/output/add" [id=984, type=Add];
"985 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [id=985, type=ReduceMean];
"986 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [id=986, type=Identity];
"987 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [id=987, type=Sub];
"988 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [id=988, type=Mul];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [id=989, type=ReduceMean];
"990 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [id=990, type=Add];
"991 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [id=991, type=Sqrt];
"992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [id=992, type=Reciprocal];
"993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [id=993, type=Mul];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [id=994, type=Mul];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [id=995, type=Sub];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [id=996, type=Mul];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [id=997, type=Add];
"998 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=998, label="998 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"999 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=999, label="999 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1000 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1000, label="1000 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1001 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1001, label="1001 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1002 bert/encoder/layer_6/intermediate/dense/MatMul" [id=1002, type=MatMul];
"1003 bert/encoder/layer_6/intermediate/dense/BiasAdd" [id=1003, type=Add];
"1004 bert/encoder/layer_6/intermediate/dense/Pow" [id=1004, type=Pow];
"1005 bert/encoder/layer_6/intermediate/dense/mul" [id=1005, type=Mul];
"1006 bert/encoder/layer_6/intermediate/dense/add" [id=1006, type=Add];
"1007 bert/encoder/layer_6/intermediate/dense/mul_1" [id=1007, type=Mul];
"1008 bert/encoder/layer_6/intermediate/dense/Tanh" [id=1008, type=Tanh];
"1009 bert/encoder/layer_6/intermediate/dense/add_1" [id=1009, type=Add];
"1010 bert/encoder/layer_6/intermediate/dense/mul_2" [id=1010, type=Mul];
"1011 bert/encoder/layer_6/intermediate/dense/mul_3" [id=1011, type=Mul];
"1012 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1012, label="1012 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1013 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1013, label="1013 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1014 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1014, label="1014 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=QuantizeLinear];
"1015 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1015, label="1015 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=DequantizeLinear];
"1016 bert/encoder/layer_6/output/dense/MatMul" [id=1016, type=MatMul];
"1017 bert/encoder/layer_6/output/dense/BiasAdd" [id=1017, type=Add];
"1018 bert/encoder/layer_6/output/add" [id=1018, type=Add];
"1019 bert/encoder/layer_6/output/LayerNorm/moments/mean" [id=1019, type=ReduceMean];
"1020 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [id=1020, type=Identity];
"1021 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [id=1021, type=Sub];
"1022 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [id=1022, type=Mul];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/variance" [id=1023, type=ReduceMean];
"1024 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [id=1024, type=Add];
"1025 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [id=1025, type=Sqrt];
"1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [id=1026, type=Reciprocal];
"1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [id=1027, type=Mul];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [id=1028, type=Mul];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [id=1029, type=Sub];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [id=1030, type=Mul];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [id=1031, type=Add];
"1032 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1032, label="1032 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1033 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1033, label="1033 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1034, label="1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1035, label="1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1036, label="1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1037, label="1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1038, label="1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1039, label="1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1040 bert/encoder/layer_7/attention/self/value/MatMul" [id=1040, type=MatMul];
"1041 bert/encoder/layer_7/attention/self/value/BiasAdd" [id=1041, type=Add];
"1042 bert/encoder/layer_7/attention/self/Reshape_2" [id=1042, type=Reshape];
"1043 bert/encoder/layer_7/attention/self/transpose_2" [id=1043, type=Transpose];
"1044 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1044, label="1044 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1045 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1045, label="1045 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1046 bert/encoder/layer_7/attention/self/query/MatMul" [id=1046, type=MatMul];
"1047 bert/encoder/layer_7/attention/self/query/BiasAdd" [id=1047, type=Add];
"1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1048, label="1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1049, label="1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1050 bert/encoder/layer_7/attention/self/Reshape" [id=1050, type=Reshape];
"1051 bert/encoder/layer_7/attention/self/transpose" [id=1051, type=Transpose];
"1052 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1052, label="1052 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1053 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1053, label="1053 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1054 bert/encoder/layer_7/attention/self/key/MatMul" [id=1054, type=MatMul];
"1055 bert/encoder/layer_7/attention/self/key/BiasAdd" [id=1055, type=Add];
"1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1056, label="1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1057, label="1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1058 bert/encoder/layer_7/attention/self/Reshape_1" [id=1058, type=Reshape];
"1059 bert/encoder/layer_7/attention/self/transpose_1" [id=1059, type=Transpose];
"1060 bert/encoder/layer_7/attention/self/MatMul__404" [id=1060, type=Transpose];
"1061 bert/encoder/layer_7/attention/self/MatMul" [id=1061, type=MatMul];
"1062 bert/encoder/layer_7/attention/self/Mul" [id=1062, type=Mul];
"1063 bert/encoder/layer_7/attention/self/add" [id=1063, type=Add];
"1064 bert/encoder/layer_7/attention/self/Softmax" [id=1064, type=Softmax];
"1065 bert/encoder/layer_7/attention/self/MatMul_1" [id=1065, type=MatMul];
"1066 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1066, label="1066 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1067 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1067, label="1067 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1068 bert/encoder/layer_7/attention/self/transpose_3" [id=1068, type=Transpose];
"1069 bert/encoder/layer_7/attention/self/Reshape_3" [id=1069, type=Reshape];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1070, label="1070 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1071, label="1071 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1072 bert/encoder/layer_7/attention/output/dense/MatMul" [id=1072, type=MatMul];
"1073 bert/encoder/layer_7/attention/output/dense/BiasAdd" [id=1073, type=Add];
"1074 bert/encoder/layer_7/attention/output/add" [id=1074, type=Add];
"1075 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [id=1075, type=ReduceMean];
"1076 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [id=1076, type=Identity];
"1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [id=1077, type=Sub];
"1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [id=1078, type=Mul];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [id=1079, type=ReduceMean];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [id=1080, type=Add];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1081, type=Sqrt];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [id=1082, type=Reciprocal];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [id=1083, type=Mul];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [id=1084, type=Mul];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [id=1085, type=Sub];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [id=1086, type=Mul];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [id=1087, type=Add];
"1088 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1088, label="1088 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1089 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1089, label="1089 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1090 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1090, label="1090 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1091 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1091, label="1091 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1092 bert/encoder/layer_7/intermediate/dense/MatMul" [id=1092, type=MatMul];
"1093 bert/encoder/layer_7/intermediate/dense/BiasAdd" [id=1093, type=Add];
"1094 bert/encoder/layer_7/intermediate/dense/Pow" [id=1094, type=Pow];
"1095 bert/encoder/layer_7/intermediate/dense/mul" [id=1095, type=Mul];
"1096 bert/encoder/layer_7/intermediate/dense/add" [id=1096, type=Add];
"1097 bert/encoder/layer_7/intermediate/dense/mul_1" [id=1097, type=Mul];
"1098 bert/encoder/layer_7/intermediate/dense/Tanh" [id=1098, type=Tanh];
"1099 bert/encoder/layer_7/intermediate/dense/add_1" [id=1099, type=Add];
"1100 bert/encoder/layer_7/intermediate/dense/mul_2" [id=1100, type=Mul];
"1101 bert/encoder/layer_7/intermediate/dense/mul_3" [id=1101, type=Mul];
"1102 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1102, label="1102 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1103 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1103, label="1103 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1104 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1104, label="1104 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=QuantizeLinear];
"1105 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1105, label="1105 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=DequantizeLinear];
"1106 bert/encoder/layer_7/output/dense/MatMul" [id=1106, type=MatMul];
"1107 bert/encoder/layer_7/output/dense/BiasAdd" [id=1107, type=Add];
"1108 bert/encoder/layer_7/output/add" [id=1108, type=Add];
"1109 bert/encoder/layer_7/output/LayerNorm/moments/mean" [id=1109, type=ReduceMean];
"1110 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [id=1110, type=Identity];
"1111 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [id=1111, type=Sub];
"1112 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [id=1112, type=Mul];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/variance" [id=1113, type=ReduceMean];
"1114 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [id=1114, type=Add];
"1115 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [id=1115, type=Sqrt];
"1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [id=1116, type=Reciprocal];
"1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [id=1117, type=Mul];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [id=1118, type=Mul];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [id=1119, type=Sub];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [id=1120, type=Mul];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [id=1121, type=Add];
"1122 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1122, label="1122 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1123 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1123, label="1123 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1124, label="1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1125, label="1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1126, label="1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1127, label="1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1128, label="1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1129, label="1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1130 bert/encoder/layer_8/attention/self/value/MatMul" [id=1130, type=MatMul];
"1131 bert/encoder/layer_8/attention/self/value/BiasAdd" [id=1131, type=Add];
"1132 bert/encoder/layer_8/attention/self/Reshape_2" [id=1132, type=Reshape];
"1133 bert/encoder/layer_8/attention/self/transpose_2" [id=1133, type=Transpose];
"1134 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1134, label="1134 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1135 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1135, label="1135 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1136 bert/encoder/layer_8/attention/self/query/MatMul" [id=1136, type=MatMul];
"1137 bert/encoder/layer_8/attention/self/query/BiasAdd" [id=1137, type=Add];
"1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1138, label="1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1139, label="1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1140 bert/encoder/layer_8/attention/self/Reshape" [id=1140, type=Reshape];
"1141 bert/encoder/layer_8/attention/self/transpose" [id=1141, type=Transpose];
"1142 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1142, label="1142 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1143 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1143, label="1143 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1144 bert/encoder/layer_8/attention/self/key/MatMul" [id=1144, type=MatMul];
"1145 bert/encoder/layer_8/attention/self/key/BiasAdd" [id=1145, type=Add];
"1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1146, label="1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1147, label="1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1148 bert/encoder/layer_8/attention/self/Reshape_1" [id=1148, type=Reshape];
"1149 bert/encoder/layer_8/attention/self/transpose_1" [id=1149, type=Transpose];
"1150 bert/encoder/layer_8/attention/self/MatMul__418" [id=1150, type=Transpose];
"1151 bert/encoder/layer_8/attention/self/MatMul" [id=1151, type=MatMul];
"1152 bert/encoder/layer_8/attention/self/Mul" [id=1152, type=Mul];
"1153 bert/encoder/layer_8/attention/self/add" [id=1153, type=Add];
"1154 bert/encoder/layer_8/attention/self/Softmax" [id=1154, type=Softmax];
"1155 bert/encoder/layer_8/attention/self/MatMul_1" [id=1155, type=MatMul];
"1156 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1156, label="1156 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1157 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1157, label="1157 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1158 bert/encoder/layer_8/attention/self/transpose_3" [id=1158, type=Transpose];
"1159 bert/encoder/layer_8/attention/self/Reshape_3" [id=1159, type=Reshape];
"1160 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1160, label="1160 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1161 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1161, label="1161 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1162 bert/encoder/layer_8/attention/output/dense/MatMul" [id=1162, type=MatMul];
"1163 bert/encoder/layer_8/attention/output/dense/BiasAdd" [id=1163, type=Add];
"1164 bert/encoder/layer_8/attention/output/add" [id=1164, type=Add];
"1165 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [id=1165, type=ReduceMean];
"1166 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [id=1166, type=Identity];
"1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [id=1167, type=Sub];
"1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [id=1168, type=Mul];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [id=1169, type=ReduceMean];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [id=1170, type=Add];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1171, type=Sqrt];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [id=1172, type=Reciprocal];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [id=1173, type=Mul];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [id=1174, type=Mul];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [id=1175, type=Sub];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [id=1176, type=Mul];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [id=1177, type=Add];
"1178 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1178, label="1178 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1179 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1179, label="1179 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1180 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1180, label="1180 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1181 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1181, label="1181 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1182 bert/encoder/layer_8/intermediate/dense/MatMul" [id=1182, type=MatMul];
"1183 bert/encoder/layer_8/intermediate/dense/BiasAdd" [id=1183, type=Add];
"1184 bert/encoder/layer_8/intermediate/dense/Pow" [id=1184, type=Pow];
"1185 bert/encoder/layer_8/intermediate/dense/mul" [id=1185, type=Mul];
"1186 bert/encoder/layer_8/intermediate/dense/add" [id=1186, type=Add];
"1187 bert/encoder/layer_8/intermediate/dense/mul_1" [id=1187, type=Mul];
"1188 bert/encoder/layer_8/intermediate/dense/Tanh" [id=1188, type=Tanh];
"1189 bert/encoder/layer_8/intermediate/dense/add_1" [id=1189, type=Add];
"1190 bert/encoder/layer_8/intermediate/dense/mul_2" [id=1190, type=Mul];
"1191 bert/encoder/layer_8/intermediate/dense/mul_3" [id=1191, type=Mul];
"1192 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1192, label="1192 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1193 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1193, label="1193 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1194 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1194, label="1194 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=QuantizeLinear];
"1195 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1195, label="1195 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=DequantizeLinear];
"1196 bert/encoder/layer_8/output/dense/MatMul" [id=1196, type=MatMul];
"1197 bert/encoder/layer_8/output/dense/BiasAdd" [id=1197, type=Add];
"1198 bert/encoder/layer_8/output/add" [id=1198, type=Add];
"1199 bert/encoder/layer_8/output/LayerNorm/moments/mean" [id=1199, type=ReduceMean];
"1200 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [id=1200, type=Identity];
"1201 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [id=1201, type=Sub];
"1202 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [id=1202, type=Mul];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/variance" [id=1203, type=ReduceMean];
"1204 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [id=1204, type=Add];
"1205 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [id=1205, type=Sqrt];
"1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [id=1206, type=Reciprocal];
"1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [id=1207, type=Mul];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [id=1208, type=Mul];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [id=1209, type=Sub];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [id=1210, type=Mul];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [id=1211, type=Add];
"1212 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1212, label="1212 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1213 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1213, label="1213 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1214, label="1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1215, label="1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1216, label="1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1217, label="1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1218, label="1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1219, label="1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1220 bert/encoder/layer_9/attention/self/value/MatMul" [id=1220, type=MatMul];
"1221 bert/encoder/layer_9/attention/self/value/BiasAdd" [id=1221, type=Add];
"1222 bert/encoder/layer_9/attention/self/Reshape_2" [id=1222, type=Reshape];
"1223 bert/encoder/layer_9/attention/self/transpose_2" [id=1223, type=Transpose];
"1224 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1224, label="1224 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1225 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1225, label="1225 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1226 bert/encoder/layer_9/attention/self/query/MatMul" [id=1226, type=MatMul];
"1227 bert/encoder/layer_9/attention/self/query/BiasAdd" [id=1227, type=Add];
"1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1228, label="1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1229, label="1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1230 bert/encoder/layer_9/attention/self/Reshape" [id=1230, type=Reshape];
"1231 bert/encoder/layer_9/attention/self/transpose" [id=1231, type=Transpose];
"1232 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1232, label="1232 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1233 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1233, label="1233 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1234 bert/encoder/layer_9/attention/self/key/MatMul" [id=1234, type=MatMul];
"1235 bert/encoder/layer_9/attention/self/key/BiasAdd" [id=1235, type=Add];
"1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1236, label="1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1237, label="1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1238 bert/encoder/layer_9/attention/self/Reshape_1" [id=1238, type=Reshape];
"1239 bert/encoder/layer_9/attention/self/transpose_1" [id=1239, type=Transpose];
"1240 bert/encoder/layer_9/attention/self/MatMul__432" [id=1240, type=Transpose];
"1241 bert/encoder/layer_9/attention/self/MatMul" [id=1241, type=MatMul];
"1242 bert/encoder/layer_9/attention/self/Mul" [id=1242, type=Mul];
"1243 bert/encoder/layer_9/attention/self/add" [id=1243, type=Add];
"1244 bert/encoder/layer_9/attention/self/Softmax" [id=1244, type=Softmax];
"1245 bert/encoder/layer_9/attention/self/MatMul_1" [id=1245, type=MatMul];
"1246 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1246, label="1246 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1247 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1247, label="1247 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1248 bert/encoder/layer_9/attention/self/transpose_3" [id=1248, type=Transpose];
"1249 bert/encoder/layer_9/attention/self/Reshape_3" [id=1249, type=Reshape];
"1250 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1250, label="1250 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1251 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1251, label="1251 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1252 bert/encoder/layer_9/attention/output/dense/MatMul" [id=1252, type=MatMul];
"1253 bert/encoder/layer_9/attention/output/dense/BiasAdd" [id=1253, type=Add];
"1254 bert/encoder/layer_9/attention/output/add" [id=1254, type=Add];
"1255 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [id=1255, type=ReduceMean];
"1256 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [id=1256, type=Identity];
"1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [id=1257, type=Sub];
"1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [id=1258, type=Mul];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [id=1259, type=ReduceMean];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [id=1260, type=Add];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1261, type=Sqrt];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [id=1262, type=Reciprocal];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [id=1263, type=Mul];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [id=1264, type=Mul];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [id=1265, type=Sub];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [id=1266, type=Mul];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [id=1267, type=Add];
"1268 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1268, label="1268 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1269 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1269, label="1269 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1270 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1270, label="1270 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1271 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1271, label="1271 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1272 bert/encoder/layer_9/intermediate/dense/MatMul" [id=1272, type=MatMul];
"1273 bert/encoder/layer_9/intermediate/dense/BiasAdd" [id=1273, type=Add];
"1274 bert/encoder/layer_9/intermediate/dense/Pow" [id=1274, type=Pow];
"1275 bert/encoder/layer_9/intermediate/dense/mul" [id=1275, type=Mul];
"1276 bert/encoder/layer_9/intermediate/dense/add" [id=1276, type=Add];
"1277 bert/encoder/layer_9/intermediate/dense/mul_1" [id=1277, type=Mul];
"1278 bert/encoder/layer_9/intermediate/dense/Tanh" [id=1278, type=Tanh];
"1279 bert/encoder/layer_9/intermediate/dense/add_1" [id=1279, type=Add];
"1280 bert/encoder/layer_9/intermediate/dense/mul_2" [id=1280, type=Mul];
"1281 bert/encoder/layer_9/intermediate/dense/mul_3" [id=1281, type=Mul];
"1282 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1282, label="1282 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1283 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1283, label="1283 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1284 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1284, label="1284 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=QuantizeLinear];
"1285 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1285, label="1285 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=DequantizeLinear];
"1286 bert/encoder/layer_9/output/dense/MatMul" [id=1286, type=MatMul];
"1287 bert/encoder/layer_9/output/dense/BiasAdd" [id=1287, type=Add];
"1288 bert/encoder/layer_9/output/add" [id=1288, type=Add];
"1289 bert/encoder/layer_9/output/LayerNorm/moments/mean" [id=1289, type=ReduceMean];
"1290 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [id=1290, type=Identity];
"1291 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [id=1291, type=Sub];
"1292 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [id=1292, type=Mul];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/variance" [id=1293, type=ReduceMean];
"1294 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [id=1294, type=Add];
"1295 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [id=1295, type=Sqrt];
"1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [id=1296, type=Reciprocal];
"1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [id=1297, type=Mul];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [id=1298, type=Mul];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [id=1299, type=Sub];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [id=1300, type=Mul];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [id=1301, type=Add];
"1302 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1302, label="1302 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1303 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1303, label="1303 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1304, label="1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1305, label="1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1306, label="1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1307, label="1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1308, label="1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1309, label="1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1310 bert/encoder/layer_10/attention/self/value/MatMul" [id=1310, type=MatMul];
"1311 bert/encoder/layer_10/attention/self/value/BiasAdd" [id=1311, type=Add];
"1312 bert/encoder/layer_10/attention/self/Reshape_2" [id=1312, type=Reshape];
"1313 bert/encoder/layer_10/attention/self/transpose_2" [id=1313, type=Transpose];
"1314 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1314, label="1314 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1315 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1315, label="1315 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1316 bert/encoder/layer_10/attention/self/query/MatMul" [id=1316, type=MatMul];
"1317 bert/encoder/layer_10/attention/self/query/BiasAdd" [id=1317, type=Add];
"1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1318, label="1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1319, label="1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1320 bert/encoder/layer_10/attention/self/Reshape" [id=1320, type=Reshape];
"1321 bert/encoder/layer_10/attention/self/transpose" [id=1321, type=Transpose];
"1322 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1322, label="1322 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1323 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1323, label="1323 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1324 bert/encoder/layer_10/attention/self/key/MatMul" [id=1324, type=MatMul];
"1325 bert/encoder/layer_10/attention/self/key/BiasAdd" [id=1325, type=Add];
"1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1326, label="1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1327, label="1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1328 bert/encoder/layer_10/attention/self/Reshape_1" [id=1328, type=Reshape];
"1329 bert/encoder/layer_10/attention/self/transpose_1" [id=1329, type=Transpose];
"1330 bert/encoder/layer_10/attention/self/MatMul__446" [id=1330, type=Transpose];
"1331 bert/encoder/layer_10/attention/self/MatMul" [id=1331, type=MatMul];
"1332 bert/encoder/layer_10/attention/self/Mul" [id=1332, type=Mul];
"1333 bert/encoder/layer_10/attention/self/add" [id=1333, type=Add];
"1334 bert/encoder/layer_10/attention/self/Softmax" [id=1334, type=Softmax];
"1335 bert/encoder/layer_10/attention/self/MatMul_1" [id=1335, type=MatMul];
"1336 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1336, label="1336 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1337 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1337, label="1337 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1338 bert/encoder/layer_10/attention/self/transpose_3" [id=1338, type=Transpose];
"1339 bert/encoder/layer_10/attention/self/Reshape_3" [id=1339, type=Reshape];
"1340 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1340, label="1340 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1341 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1341, label="1341 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1342 bert/encoder/layer_10/attention/output/dense/MatMul" [id=1342, type=MatMul];
"1343 bert/encoder/layer_10/attention/output/dense/BiasAdd" [id=1343, type=Add];
"1344 bert/encoder/layer_10/attention/output/add" [id=1344, type=Add];
"1345 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [id=1345, type=ReduceMean];
"1346 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [id=1346, type=Identity];
"1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [id=1347, type=Sub];
"1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [id=1348, type=Mul];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [id=1349, type=ReduceMean];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [id=1350, type=Add];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1351, type=Sqrt];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [id=1352, type=Reciprocal];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [id=1353, type=Mul];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [id=1354, type=Mul];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [id=1355, type=Sub];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [id=1356, type=Mul];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [id=1357, type=Add];
"1358 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1358, label="1358 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1359 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1359, label="1359 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1360 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1360, label="1360 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1361 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1361, label="1361 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1362 bert/encoder/layer_10/intermediate/dense/MatMul" [id=1362, type=MatMul];
"1363 bert/encoder/layer_10/intermediate/dense/BiasAdd" [id=1363, type=Add];
"1364 bert/encoder/layer_10/intermediate/dense/Pow" [id=1364, type=Pow];
"1365 bert/encoder/layer_10/intermediate/dense/mul" [id=1365, type=Mul];
"1366 bert/encoder/layer_10/intermediate/dense/add" [id=1366, type=Add];
"1367 bert/encoder/layer_10/intermediate/dense/mul_1" [id=1367, type=Mul];
"1368 bert/encoder/layer_10/intermediate/dense/Tanh" [id=1368, type=Tanh];
"1369 bert/encoder/layer_10/intermediate/dense/add_1" [id=1369, type=Add];
"1370 bert/encoder/layer_10/intermediate/dense/mul_2" [id=1370, type=Mul];
"1371 bert/encoder/layer_10/intermediate/dense/mul_3" [id=1371, type=Mul];
"1372 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1372, label="1372 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1373 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1373, label="1373 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1374 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1374, label="1374 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=QuantizeLinear];
"1375 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1375, label="1375 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=DequantizeLinear];
"1376 bert/encoder/layer_10/output/dense/MatMul" [id=1376, type=MatMul];
"1377 bert/encoder/layer_10/output/dense/BiasAdd" [id=1377, type=Add];
"1378 bert/encoder/layer_10/output/add" [id=1378, type=Add];
"1379 bert/encoder/layer_10/output/LayerNorm/moments/mean" [id=1379, type=ReduceMean];
"1380 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [id=1380, type=Identity];
"1381 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [id=1381, type=Sub];
"1382 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [id=1382, type=Mul];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/variance" [id=1383, type=ReduceMean];
"1384 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [id=1384, type=Add];
"1385 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [id=1385, type=Sqrt];
"1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [id=1386, type=Reciprocal];
"1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [id=1387, type=Mul];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [id=1388, type=Mul];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [id=1389, type=Sub];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [id=1390, type=Mul];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [id=1391, type=Add];
"1392 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1392, label="1392 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1393 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1393, label="1393 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1394, label="1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1395, label="1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1396, label="1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1397, label="1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1398, label="1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1399, label="1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1400 bert/encoder/layer_11/attention/self/value/MatMul" [id=1400, type=MatMul];
"1401 bert/encoder/layer_11/attention/self/value/BiasAdd" [id=1401, type=Add];
"1402 bert/encoder/layer_11/attention/self/Reshape_2" [id=1402, type=Reshape];
"1403 bert/encoder/layer_11/attention/self/transpose_2" [id=1403, type=Transpose];
"1404 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1404, label="1404 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1405 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1405, label="1405 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1406 bert/encoder/layer_11/attention/self/query/MatMul" [id=1406, type=MatMul];
"1407 bert/encoder/layer_11/attention/self/query/BiasAdd" [id=1407, type=Add];
"1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1408, label="1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1409, label="1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1410 bert/encoder/layer_11/attention/self/Reshape" [id=1410, type=Reshape];
"1411 bert/encoder/layer_11/attention/self/transpose" [id=1411, type=Transpose];
"1412 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1412, label="1412 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1413 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1413, label="1413 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1414 bert/encoder/layer_11/attention/self/key/MatMul" [id=1414, type=MatMul];
"1415 bert/encoder/layer_11/attention/self/key/BiasAdd" [id=1415, type=Add];
"1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1416, label="1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1417, label="1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1418 bert/encoder/layer_11/attention/self/Reshape_1" [id=1418, type=Reshape];
"1419 bert/encoder/layer_11/attention/self/transpose_1" [id=1419, type=Transpose];
"1420 bert/encoder/layer_11/attention/self/MatMul__460" [id=1420, type=Transpose];
"1421 bert/encoder/layer_11/attention/self/MatMul" [id=1421, type=MatMul];
"1422 bert/encoder/layer_11/attention/self/Mul" [id=1422, type=Mul];
"1423 bert/encoder/layer_11/attention/self/add" [id=1423, type=Add];
"1424 bert/encoder/layer_11/attention/self/Softmax" [id=1424, type=Softmax];
"1425 bert/encoder/layer_11/attention/self/MatMul_1" [id=1425, type=MatMul];
"1426 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1426, label="1426 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1427 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1427, label="1427 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1428 bert/encoder/layer_11/attention/self/transpose_3" [id=1428, type=Transpose];
"1429 bert/encoder/layer_11/attention/self/Reshape_3" [id=1429, type=Reshape];
"1430 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1430, label="1430 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1431 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1431, label="1431 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1432 bert/encoder/layer_11/attention/output/dense/MatMul" [id=1432, type=MatMul];
"1433 bert/encoder/layer_11/attention/output/dense/BiasAdd" [id=1433, type=Add];
"1434 bert/encoder/layer_11/attention/output/add" [id=1434, type=Add];
"1435 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [id=1435, type=ReduceMean];
"1436 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [id=1436, type=Identity];
"1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [id=1437, type=Sub];
"1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [id=1438, type=Mul];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [id=1439, type=ReduceMean];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [id=1440, type=Add];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1441, type=Sqrt];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [id=1442, type=Reciprocal];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [id=1443, type=Mul];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [id=1444, type=Mul];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [id=1445, type=Sub];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [id=1446, type=Mul];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [id=1447, type=Add];
"1448 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1448, label="1448 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1449 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1449, label="1449 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1450 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1450, label="1450 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1451 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1451, label="1451 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1452 bert/encoder/layer_11/intermediate/dense/MatMul" [id=1452, type=MatMul];
"1453 bert/encoder/layer_11/intermediate/dense/BiasAdd" [id=1453, type=Add];
"1454 bert/encoder/layer_11/intermediate/dense/Pow" [id=1454, type=Pow];
"1455 bert/encoder/layer_11/intermediate/dense/mul" [id=1455, type=Mul];
"1456 bert/encoder/layer_11/intermediate/dense/add" [id=1456, type=Add];
"1457 bert/encoder/layer_11/intermediate/dense/mul_1" [id=1457, type=Mul];
"1458 bert/encoder/layer_11/intermediate/dense/Tanh" [id=1458, type=Tanh];
"1459 bert/encoder/layer_11/intermediate/dense/add_1" [id=1459, type=Add];
"1460 bert/encoder/layer_11/intermediate/dense/mul_2" [id=1460, type=Mul];
"1461 bert/encoder/layer_11/intermediate/dense/mul_3" [id=1461, type=Mul];
"1462 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1462, label="1462 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1463 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1463, label="1463 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1464 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1464, label="1464 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=QuantizeLinear];
"1465 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1465, label="1465 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=DequantizeLinear];
"1466 bert/encoder/layer_11/output/dense/MatMul" [id=1466, type=MatMul];
"1467 bert/encoder/layer_11/output/dense/BiasAdd" [id=1467, type=Add];
"1468 bert/encoder/layer_11/output/add" [id=1468, type=Add];
"1469 bert/encoder/layer_11/output/LayerNorm/moments/mean" [id=1469, type=ReduceMean];
"1470 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [id=1470, type=Identity];
"1471 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [id=1471, type=Sub];
"1472 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [id=1472, type=Mul];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/variance" [id=1473, type=ReduceMean];
"1474 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [id=1474, type=Add];
"1475 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [id=1475, type=Sqrt];
"1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [id=1476, type=Reciprocal];
"1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [id=1477, type=Mul];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [id=1478, type=Mul];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [id=1479, type=Sub];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [id=1480, type=Mul];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [id=1481, type=Add];
"1482 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1482, label="1482 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1483 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1483, label="1483 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1484 bert/encoder/Reshape_13" [id=1484, type=Reshape];
"1485 Shape_1" [id=1485, type=Shape];
"1486 Shape_1__472" [id=1486, type=Cast];
"1487 strided_slice_1" [id=1487, type=Slice];
"1488 strided_slice_1__476" [id=1488, type=Squeeze];
"1489 strided_slice_1__477" [id=1489, type=Cast];
"1490 mul" [id=1490, type=Mul];
"1491 Reshape/shape_Unsqueeze__482" [id=1491, type=Unsqueeze];
"1492 Reshape/shape_Concat__484" [id=1492, type=Concat];
"1493 Reshape__485" [id=1493, type=Cast];
"1494 Reshape_1/shape_Unsqueeze__478" [id=1494, type=Unsqueeze];
"1495 Reshape_1/shape_Concat__481" [id=1495, type=Concat];
"1496 Reshape_1__487" [id=1496, type=Cast];
"1497 Reshape" [id=1497, type=Reshape];
"1498 QuantizeLinear_MatMul__486^0_1" [id=1498, label="1498 QuantizeLinear_MatMul__486:0_1", type=QuantizeLinear];
"1499 DequantizeLinear_MatMul__486^0_1" [id=1499, label="1499 DequantizeLinear_MatMul__486:0_1", type=DequantizeLinear];
"1500 MatMul" [id=1500, type=MatMul];
"1501 BiasAdd" [id=1501, type=Add];
"1502 Reshape_1" [id=1502, type=Reshape];
"1503 transpose" [id=1503, type=Transpose];
"1504 unstack" [id=1504, type=Split];
"1505 unstack__490" [id=1505, type=Squeeze];
"1506 unstack_graph_outputs_Identity__4" [id=1506, type=Identity];
"1507 unstack__488" [id=1507, type=Squeeze];
"1508 unstack_graph_outputs_Identity__7" [id=1508, type=Identity];
"1509 nncf_model_input_0" [id=1509, type=nncf_model_input];
"1510 nncf_model_input_1" [id=1510, type=nncf_model_input];
"1511 nncf_model_input_2" [id=1511, type=nncf_model_input];
"1512 nncf_model_input_3" [id=1512, type=nncf_model_input];
"1513 nncf_model_output_0" [id=1513, type=nncf_model_output];
"1514 nncf_model_output_1" [id=1514, type=nncf_model_output];
"1515 nncf_model_output_2" [id=1515, type=nncf_model_output];
"0 unique_ids_graph_outputs_Identity__10" -> "1515 nncf_model_output_2"  [label="[-1]", style=dashed];
"1 bert/encoder/ones/packed_Unsqueeze__20" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"2 bert/encoder/ones/packed_Unsqueeze__19" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"123 bert/encoder/Shape" -> "124 bert/encoder/Shape__12"  [label="[2]", style=dashed];
"124 bert/encoder/Shape__12" -> "125 bert/encoder/strided_slice"  [label="[2]", style=solid];
"125 bert/encoder/strided_slice" -> "126 bert/encoder/strided_slice__16"  [label="[1]", style=solid];
"126 bert/encoder/strided_slice__16" -> "127 bert/encoder/strided_slice__17"  [label="[]", style=solid];
"127 bert/encoder/strided_slice__17" -> "128 bert/encoder/ones/packed_Unsqueeze__18"  [label="[]", style=dashed];
"127 bert/encoder/strided_slice__17" -> "135 bert/encoder/Reshape/shape_Unsqueeze__23"  [label="[]", style=dashed];
"128 bert/encoder/ones/packed_Unsqueeze__18" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"129 bert/encoder/ones/packed_Concat__21" -> "130 bert/encoder/ones__22"  [label="[3]", style=dashed];
"130 bert/encoder/ones__22" -> "131 bert/encoder/ones"  [label="[3]", style=dashed];
"131 bert/encoder/ones" -> "142 bert/encoder/mul"  [label="[-1, -1, -1]", style=solid];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"134 bert/encoder/Reshape_1__302" -> "405 bert/encoder/Reshape_1"  [label="[2]", style=dashed];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"138 bert/encoder/Reshape/shape_Concat__26" -> "139 bert/encoder/Reshape__27"  [label="[3]", style=dashed];
"139 bert/encoder/Reshape__27" -> "140 bert/encoder/Reshape"  [label="[3]", style=dashed];
"140 bert/encoder/Reshape" -> "141 bert/encoder/Cast"  [label="[]", style=dashed];
"141 bert/encoder/Cast" -> "142 bert/encoder/mul"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "143 bert/encoder/layer_9/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "146 bert/encoder/layer_8/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "149 bert/encoder/layer_7/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "152 bert/encoder/layer_6/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "155 bert/encoder/layer_5/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "158 bert/encoder/layer_4/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "161 bert/encoder/layer_3/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "164 bert/encoder/layer_2/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "167 bert/encoder/layer_11/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "170 bert/encoder/layer_10/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "173 bert/encoder/layer_1/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "176 bert/encoder/layer_0/attention/self/ExpandDims"  [label="[]", style=solid];
"143 bert/encoder/layer_9/attention/self/ExpandDims" -> "144 bert/encoder/layer_9/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"144 bert/encoder/layer_9/attention/self/sub" -> "145 bert/encoder/layer_9/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"145 bert/encoder/layer_9/attention/self/mul_1" -> "1243 bert/encoder/layer_9/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"146 bert/encoder/layer_8/attention/self/ExpandDims" -> "147 bert/encoder/layer_8/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"147 bert/encoder/layer_8/attention/self/sub" -> "148 bert/encoder/layer_8/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"148 bert/encoder/layer_8/attention/self/mul_1" -> "1153 bert/encoder/layer_8/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"149 bert/encoder/layer_7/attention/self/ExpandDims" -> "150 bert/encoder/layer_7/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"150 bert/encoder/layer_7/attention/self/sub" -> "151 bert/encoder/layer_7/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"151 bert/encoder/layer_7/attention/self/mul_1" -> "1063 bert/encoder/layer_7/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"152 bert/encoder/layer_6/attention/self/ExpandDims" -> "153 bert/encoder/layer_6/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"153 bert/encoder/layer_6/attention/self/sub" -> "154 bert/encoder/layer_6/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"154 bert/encoder/layer_6/attention/self/mul_1" -> "973 bert/encoder/layer_6/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"155 bert/encoder/layer_5/attention/self/ExpandDims" -> "156 bert/encoder/layer_5/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"156 bert/encoder/layer_5/attention/self/sub" -> "157 bert/encoder/layer_5/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"157 bert/encoder/layer_5/attention/self/mul_1" -> "883 bert/encoder/layer_5/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"158 bert/encoder/layer_4/attention/self/ExpandDims" -> "159 bert/encoder/layer_4/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"159 bert/encoder/layer_4/attention/self/sub" -> "160 bert/encoder/layer_4/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"160 bert/encoder/layer_4/attention/self/mul_1" -> "793 bert/encoder/layer_4/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"161 bert/encoder/layer_3/attention/self/ExpandDims" -> "162 bert/encoder/layer_3/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"162 bert/encoder/layer_3/attention/self/sub" -> "163 bert/encoder/layer_3/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"163 bert/encoder/layer_3/attention/self/mul_1" -> "703 bert/encoder/layer_3/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"164 bert/encoder/layer_2/attention/self/ExpandDims" -> "165 bert/encoder/layer_2/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"165 bert/encoder/layer_2/attention/self/sub" -> "166 bert/encoder/layer_2/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"166 bert/encoder/layer_2/attention/self/mul_1" -> "613 bert/encoder/layer_2/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"167 bert/encoder/layer_11/attention/self/ExpandDims" -> "168 bert/encoder/layer_11/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"168 bert/encoder/layer_11/attention/self/sub" -> "169 bert/encoder/layer_11/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"169 bert/encoder/layer_11/attention/self/mul_1" -> "1423 bert/encoder/layer_11/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"170 bert/encoder/layer_10/attention/self/ExpandDims" -> "171 bert/encoder/layer_10/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"171 bert/encoder/layer_10/attention/self/sub" -> "172 bert/encoder/layer_10/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"172 bert/encoder/layer_10/attention/self/mul_1" -> "1333 bert/encoder/layer_10/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"173 bert/encoder/layer_1/attention/self/ExpandDims" -> "174 bert/encoder/layer_1/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"174 bert/encoder/layer_1/attention/self/sub" -> "175 bert/encoder/layer_1/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"175 bert/encoder/layer_1/attention/self/mul_1" -> "523 bert/encoder/layer_1/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"176 bert/encoder/layer_0/attention/self/ExpandDims" -> "177 bert/encoder/layer_0/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"177 bert/encoder/layer_0/attention/self/sub" -> "178 bert/encoder/layer_0/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"178 bert/encoder/layer_0/attention/self/mul_1" -> "433 bert/encoder/layer_0/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"179 bert/embeddings/Slice" -> "181 bert/embeddings/Reshape_4"  [label="[256, 768]", style=solid];
"180 bert/embeddings/Reshape_4__42" -> "181 bert/embeddings/Reshape_4"  [label="[3]", style=dashed];
"181 bert/embeddings/Reshape_4" -> "227 bert/embeddings/add_1"  [label="[]", style=solid];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"184 bert/embeddings/Reshape_2__43" -> "185 bert/embeddings/Reshape_2"  [label="[1]", style=dashed];
"185 bert/embeddings/Reshape_2" -> "219 bert/embeddings/one_hot"  [label="[]", style=dashed];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"188 bert/embeddings/Reshape__59" -> "198 bert/embeddings/Reshape"  [label="[1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "190 bert/embeddings/Shape"  [label="[-1, 256, 1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "198 bert/embeddings/Reshape"  [label="[-1, 256, 1]", style=dashed];
"190 bert/embeddings/Shape" -> "191 bert/embeddings/Shape__49"  [label="[3]", style=dashed];
"191 bert/embeddings/Shape__49" -> "192 bert/embeddings/strided_slice"  [label="[3]", style=solid];
"192 bert/embeddings/strided_slice" -> "193 bert/embeddings/strided_slice__53"  [label="[1]", style=solid];
"193 bert/embeddings/strided_slice__53" -> "194 bert/embeddings/strided_slice__54"  [label="[]", style=solid];
"194 bert/embeddings/strided_slice__54" -> "195 bert/embeddings/Reshape_1/shape_Unsqueeze__55"  [label="[]", style=dashed];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"196 bert/embeddings/Reshape_1/shape_Concat__58" -> "197 bert/embeddings/Reshape_1__60"  [label="[3]", style=dashed];
"197 bert/embeddings/Reshape_1__60" -> "202 bert/embeddings/Reshape_1"  [label="[3]", style=dashed];
"198 bert/embeddings/Reshape" -> "201 bert/embeddings/GatherV2"  [label="[]", style=dashed];
"199 QuantizeLinear_bert/embeddings/word_embeddings^0_1" -> "200 DequantizeLinear_bert/embeddings/word_embeddings^0_1"  [label="[30522, 768]", style=dashed];
"200 DequantizeLinear_bert/embeddings/word_embeddings^0_1" -> "201 bert/embeddings/GatherV2"  [label="[30522, 768]", style=solid];
"201 bert/embeddings/GatherV2" -> "202 bert/embeddings/Reshape_1"  [label="[]", style=solid];
"202 bert/embeddings/Reshape_1" -> "203 bert/embeddings/Shape_1"  [label="[]", style=solid];
"202 bert/embeddings/Reshape_1" -> "226 bert/embeddings/add"  [label="[]", style=solid];
"203 bert/embeddings/Shape_1" -> "204 bert/embeddings/Shape_1__61"  [label="[-1]", style=dashed];
"204 bert/embeddings/Shape_1__61" -> "205 bert/embeddings/strided_slice_1"  [label="[-1]", style=solid];
"205 bert/embeddings/strided_slice_1" -> "206 bert/embeddings/strided_slice_1__65"  [label="[-1]", style=solid];
"206 bert/embeddings/strided_slice_1__65" -> "207 bert/embeddings/strided_slice_1__66"  [label="[]", style=solid];
"207 bert/embeddings/strided_slice_1__66" -> "208 bert/embeddings/Reshape_3/shape_Unsqueeze__67"  [label="[]", style=dashed];
"208 bert/embeddings/Reshape_3/shape_Unsqueeze__67" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"209 bert/embeddings/Reshape_3/shape_Concat__70" -> "210 bert/embeddings/Reshape_3__71"  [label="[3]", style=dashed];
"210 bert/embeddings/Reshape_3__71" -> "225 bert/embeddings/Reshape_3"  [label="[3]", style=dashed];
"211 Unsqueeze__46" -> "218 Concat__47"  [label="[1]", style=solid];
"212 Unsqueeze__45" -> "218 Concat__47"  [label="[1]", style=solid];
"213 Unsqueeze__44" -> "219 bert/embeddings/one_hot"  [label="[1]", style=dashed];
"214 Reshape_1/shape_Unsqueeze__480" -> "1495 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"215 Reshape_1/shape_Unsqueeze__479" -> "1495 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"216 Reshape/shape_Unsqueeze__483" -> "1492 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"217 MatMul__486" -> "1498 QuantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=solid];
"218 Concat__47" -> "219 bert/embeddings/one_hot"  [label="[2]", style=solid];
"219 bert/embeddings/one_hot" -> "220 QuantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=solid];
"220 QuantizeLinear_bert/embeddings/one_hot^0_1" -> "221 DequantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=dashed];
"221 DequantizeLinear_bert/embeddings/one_hot^0_1" -> "224 bert/embeddings/MatMul"  [label="[]", style=solid];
"222 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1"  [label="[2, 768]", style=dashed];
"223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "224 bert/embeddings/MatMul"  [label="[2, 768]", style=solid];
"224 bert/embeddings/MatMul" -> "225 bert/embeddings/Reshape_3"  [label="[]", style=solid];
"225 bert/embeddings/Reshape_3" -> "226 bert/embeddings/add"  [label="[]", style=solid];
"226 bert/embeddings/add" -> "227 bert/embeddings/add_1"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "228 bert/embeddings/LayerNorm/moments/mean"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "230 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/mean" -> "229 bert/embeddings/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/mean" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"229 bert/embeddings/LayerNorm/moments/StopGradient" -> "230 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"230 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "231 bert/embeddings/LayerNorm/moments/SquaredDifference__72"  [label="[]", style=solid];
"231 bert/embeddings/LayerNorm/moments/SquaredDifference__72" -> "232 bert/embeddings/LayerNorm/moments/variance"  [label="[]", style=solid];
"232 bert/embeddings/LayerNorm/moments/variance" -> "233 bert/embeddings/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"233 bert/embeddings/LayerNorm/batchnorm/add" -> "234 bert/embeddings/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"234 bert/embeddings/LayerNorm/batchnorm/Rsqrt" -> "235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74"  [label="[]", style=solid];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" -> "236 bert/embeddings/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" -> "238 bert/embeddings/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"238 bert/embeddings/LayerNorm/batchnorm/sub" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "241 bert/encoder/Shape_2"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "405 bert/encoder/Reshape_1"  [label="[]", style=solid];
"241 bert/encoder/Shape_2" -> "242 bert/encoder/Shape_2__76"  [label="[-1]", style=dashed];
"242 bert/encoder/Shape_2__76" -> "243 bert/encoder/strided_slice_2"  [label="[-1]", style=solid];
"243 bert/encoder/strided_slice_2" -> "244 bert/encoder/strided_slice_2__80"  [label="[-1]", style=solid];
"244 bert/encoder/strided_slice_2__80" -> "245 bert/encoder/strided_slice_2__81"  [label="[]", style=solid];
"245 bert/encoder/strided_slice_2__81" -> "246 bert/encoder/layer_9/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "259 bert/encoder/layer_8/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "272 bert/encoder/layer_7/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "285 bert/encoder/layer_6/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "298 bert/encoder/layer_5/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "311 bert/encoder/layer_4/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "324 bert/encoder/layer_3/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "337 bert/encoder/layer_2/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "350 bert/encoder/layer_11/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "363 bert/encoder/layer_10/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "376 bert/encoder/layer_1/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "389 bert/encoder/layer_0/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "402 bert/encoder/Reshape_13/shape_Unsqueeze__298"  [label="[]", style=dashed];
"246 bert/encoder/layer_9/attention/self/mul_2" -> "247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82"  [label="[]", style=dashed];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" -> "249 bert/encoder/layer_9/attention/self/Reshape_3__434"  [label="[2]", style=dashed];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" -> "1249 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[2]", style=dashed];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" -> "252 bert/encoder/layer_9/attention/self/Reshape_2__429"  [label="[4]", style=dashed];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" -> "1222 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[4]", style=dashed];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" -> "255 bert/encoder/layer_9/attention/self/Reshape_1__431"  [label="[4]", style=dashed];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" -> "1238 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[4]", style=dashed];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" -> "258 bert/encoder/layer_9/attention/self/Reshape__430"  [label="[4]", style=dashed];
"258 bert/encoder/layer_9/attention/self/Reshape__430" -> "1230 bert/encoder/layer_9/attention/self/Reshape"  [label="[4]", style=dashed];
"259 bert/encoder/layer_8/attention/self/mul_2" -> "260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100"  [label="[]", style=dashed];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" -> "262 bert/encoder/layer_8/attention/self/Reshape_3__420"  [label="[2]", style=dashed];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" -> "1159 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[2]", style=dashed];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" -> "265 bert/encoder/layer_8/attention/self/Reshape_2__415"  [label="[4]", style=dashed];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" -> "1132 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[4]", style=dashed];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" -> "268 bert/encoder/layer_8/attention/self/Reshape_1__417"  [label="[4]", style=dashed];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" -> "1148 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[4]", style=dashed];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" -> "271 bert/encoder/layer_8/attention/self/Reshape__416"  [label="[4]", style=dashed];
"271 bert/encoder/layer_8/attention/self/Reshape__416" -> "1140 bert/encoder/layer_8/attention/self/Reshape"  [label="[4]", style=dashed];
"272 bert/encoder/layer_7/attention/self/mul_2" -> "273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118"  [label="[]", style=dashed];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" -> "275 bert/encoder/layer_7/attention/self/Reshape_3__406"  [label="[2]", style=dashed];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" -> "1069 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[2]", style=dashed];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" -> "278 bert/encoder/layer_7/attention/self/Reshape_2__401"  [label="[4]", style=dashed];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" -> "1042 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[4]", style=dashed];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" -> "281 bert/encoder/layer_7/attention/self/Reshape_1__403"  [label="[4]", style=dashed];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" -> "1058 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[4]", style=dashed];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" -> "284 bert/encoder/layer_7/attention/self/Reshape__402"  [label="[4]", style=dashed];
"284 bert/encoder/layer_7/attention/self/Reshape__402" -> "1050 bert/encoder/layer_7/attention/self/Reshape"  [label="[4]", style=dashed];
"285 bert/encoder/layer_6/attention/self/mul_2" -> "286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136"  [label="[]", style=dashed];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" -> "288 bert/encoder/layer_6/attention/self/Reshape_3__392"  [label="[2]", style=dashed];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" -> "979 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[2]", style=dashed];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" -> "291 bert/encoder/layer_6/attention/self/Reshape_2__387"  [label="[4]", style=dashed];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" -> "952 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[4]", style=dashed];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" -> "294 bert/encoder/layer_6/attention/self/Reshape_1__389"  [label="[4]", style=dashed];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" -> "968 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[4]", style=dashed];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" -> "297 bert/encoder/layer_6/attention/self/Reshape__388"  [label="[4]", style=dashed];
"297 bert/encoder/layer_6/attention/self/Reshape__388" -> "960 bert/encoder/layer_6/attention/self/Reshape"  [label="[4]", style=dashed];
"298 bert/encoder/layer_5/attention/self/mul_2" -> "299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154"  [label="[]", style=dashed];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" -> "301 bert/encoder/layer_5/attention/self/Reshape_3__378"  [label="[2]", style=dashed];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" -> "889 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[2]", style=dashed];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" -> "304 bert/encoder/layer_5/attention/self/Reshape_2__373"  [label="[4]", style=dashed];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" -> "862 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[4]", style=dashed];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" -> "307 bert/encoder/layer_5/attention/self/Reshape_1__375"  [label="[4]", style=dashed];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" -> "878 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[4]", style=dashed];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" -> "310 bert/encoder/layer_5/attention/self/Reshape__374"  [label="[4]", style=dashed];
"310 bert/encoder/layer_5/attention/self/Reshape__374" -> "870 bert/encoder/layer_5/attention/self/Reshape"  [label="[4]", style=dashed];
"311 bert/encoder/layer_4/attention/self/mul_2" -> "312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172"  [label="[]", style=dashed];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" -> "314 bert/encoder/layer_4/attention/self/Reshape_3__364"  [label="[2]", style=dashed];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" -> "799 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[2]", style=dashed];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" -> "317 bert/encoder/layer_4/attention/self/Reshape_2__359"  [label="[4]", style=dashed];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" -> "772 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[4]", style=dashed];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" -> "320 bert/encoder/layer_4/attention/self/Reshape_1__361"  [label="[4]", style=dashed];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" -> "788 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[4]", style=dashed];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" -> "323 bert/encoder/layer_4/attention/self/Reshape__360"  [label="[4]", style=dashed];
"323 bert/encoder/layer_4/attention/self/Reshape__360" -> "780 bert/encoder/layer_4/attention/self/Reshape"  [label="[4]", style=dashed];
"324 bert/encoder/layer_3/attention/self/mul_2" -> "325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190"  [label="[]", style=dashed];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" -> "327 bert/encoder/layer_3/attention/self/Reshape_3__350"  [label="[2]", style=dashed];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" -> "709 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[2]", style=dashed];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" -> "330 bert/encoder/layer_3/attention/self/Reshape_2__345"  [label="[4]", style=dashed];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" -> "682 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[4]", style=dashed];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" -> "333 bert/encoder/layer_3/attention/self/Reshape_1__347"  [label="[4]", style=dashed];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" -> "698 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[4]", style=dashed];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" -> "336 bert/encoder/layer_3/attention/self/Reshape__346"  [label="[4]", style=dashed];
"336 bert/encoder/layer_3/attention/self/Reshape__346" -> "690 bert/encoder/layer_3/attention/self/Reshape"  [label="[4]", style=dashed];
"337 bert/encoder/layer_2/attention/self/mul_2" -> "338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208"  [label="[]", style=dashed];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" -> "340 bert/encoder/layer_2/attention/self/Reshape_3__336"  [label="[2]", style=dashed];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" -> "619 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[2]", style=dashed];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" -> "343 bert/encoder/layer_2/attention/self/Reshape_2__331"  [label="[4]", style=dashed];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" -> "592 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[4]", style=dashed];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" -> "346 bert/encoder/layer_2/attention/self/Reshape_1__333"  [label="[4]", style=dashed];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" -> "608 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[4]", style=dashed];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" -> "349 bert/encoder/layer_2/attention/self/Reshape__332"  [label="[4]", style=dashed];
"349 bert/encoder/layer_2/attention/self/Reshape__332" -> "600 bert/encoder/layer_2/attention/self/Reshape"  [label="[4]", style=dashed];
"350 bert/encoder/layer_11/attention/self/mul_2" -> "351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226"  [label="[]", style=dashed];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" -> "353 bert/encoder/layer_11/attention/self/Reshape_3__462"  [label="[2]", style=dashed];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" -> "1429 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[2]", style=dashed];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" -> "356 bert/encoder/layer_11/attention/self/Reshape_2__457"  [label="[4]", style=dashed];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" -> "1402 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[4]", style=dashed];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" -> "359 bert/encoder/layer_11/attention/self/Reshape_1__459"  [label="[4]", style=dashed];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" -> "1418 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[4]", style=dashed];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" -> "362 bert/encoder/layer_11/attention/self/Reshape__458"  [label="[4]", style=dashed];
"362 bert/encoder/layer_11/attention/self/Reshape__458" -> "1410 bert/encoder/layer_11/attention/self/Reshape"  [label="[4]", style=dashed];
"363 bert/encoder/layer_10/attention/self/mul_2" -> "364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244"  [label="[]", style=dashed];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" -> "366 bert/encoder/layer_10/attention/self/Reshape_3__448"  [label="[2]", style=dashed];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" -> "1339 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[2]", style=dashed];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" -> "369 bert/encoder/layer_10/attention/self/Reshape_2__443"  [label="[4]", style=dashed];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" -> "1312 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[4]", style=dashed];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" -> "372 bert/encoder/layer_10/attention/self/Reshape_1__445"  [label="[4]", style=dashed];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" -> "1328 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[4]", style=dashed];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" -> "375 bert/encoder/layer_10/attention/self/Reshape__444"  [label="[4]", style=dashed];
"375 bert/encoder/layer_10/attention/self/Reshape__444" -> "1320 bert/encoder/layer_10/attention/self/Reshape"  [label="[4]", style=dashed];
"376 bert/encoder/layer_1/attention/self/mul_2" -> "377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262"  [label="[]", style=dashed];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" -> "379 bert/encoder/layer_1/attention/self/Reshape_3__322"  [label="[2]", style=dashed];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" -> "529 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[2]", style=dashed];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" -> "382 bert/encoder/layer_1/attention/self/Reshape_2__317"  [label="[4]", style=dashed];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" -> "502 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[4]", style=dashed];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" -> "385 bert/encoder/layer_1/attention/self/Reshape_1__319"  [label="[4]", style=dashed];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" -> "518 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[4]", style=dashed];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" -> "388 bert/encoder/layer_1/attention/self/Reshape__318"  [label="[4]", style=dashed];
"388 bert/encoder/layer_1/attention/self/Reshape__318" -> "510 bert/encoder/layer_1/attention/self/Reshape"  [label="[4]", style=dashed];
"389 bert/encoder/layer_0/attention/self/mul_2" -> "390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280"  [label="[]", style=dashed];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" -> "392 bert/encoder/layer_0/attention/self/Reshape_3__308"  [label="[2]", style=dashed];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" -> "439 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[2]", style=dashed];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" -> "395 bert/encoder/layer_0/attention/self/Reshape_2__303"  [label="[4]", style=dashed];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" -> "412 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[4]", style=dashed];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" -> "398 bert/encoder/layer_0/attention/self/Reshape_1__305"  [label="[4]", style=dashed];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" -> "428 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[4]", style=dashed];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" -> "401 bert/encoder/layer_0/attention/self/Reshape__304"  [label="[4]", style=dashed];
"401 bert/encoder/layer_0/attention/self/Reshape__304" -> "420 bert/encoder/layer_0/attention/self/Reshape"  [label="[4]", style=dashed];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"403 bert/encoder/Reshape_13/shape_Concat__301" -> "404 bert/encoder/Reshape_13__471"  [label="[3]", style=dashed];
"404 bert/encoder/Reshape_13__471" -> "1484 bert/encoder/Reshape_13"  [label="[3]", style=dashed];
"405 bert/encoder/Reshape_1" -> "406 QuantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "444 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_1" -> "407 DequantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=dashed];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "410 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[]", style=solid];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "416 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[]", style=solid];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "424 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[]", style=solid];
"408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "410 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"410 bert/encoder/layer_0/attention/self/value/MatMul" -> "411 bert/encoder/layer_0/attention/self/value/BiasAdd"  [label="[]", style=solid];
"411 bert/encoder/layer_0/attention/self/value/BiasAdd" -> "412 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[]", style=solid];
"412 bert/encoder/layer_0/attention/self/Reshape_2" -> "413 bert/encoder/layer_0/attention/self/transpose_2"  [label="[]", style=solid];
"413 bert/encoder/layer_0/attention/self/transpose_2" -> "435 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"414 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "415 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"415 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "416 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"416 bert/encoder/layer_0/attention/self/query/MatMul" -> "417 bert/encoder/layer_0/attention/self/query/BiasAdd"  [label="[]", style=solid];
"417 bert/encoder/layer_0/attention/self/query/BiasAdd" -> "418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "420 bert/encoder/layer_0/attention/self/Reshape"  [label="[]", style=solid];
"420 bert/encoder/layer_0/attention/self/Reshape" -> "421 bert/encoder/layer_0/attention/self/transpose"  [label="[]", style=solid];
"421 bert/encoder/layer_0/attention/self/transpose" -> "431 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "423 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "424 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"424 bert/encoder/layer_0/attention/self/key/MatMul" -> "425 bert/encoder/layer_0/attention/self/key/BiasAdd"  [label="[]", style=solid];
"425 bert/encoder/layer_0/attention/self/key/BiasAdd" -> "426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "428 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[]", style=solid];
"428 bert/encoder/layer_0/attention/self/Reshape_1" -> "429 bert/encoder/layer_0/attention/self/transpose_1"  [label="[]", style=solid];
"429 bert/encoder/layer_0/attention/self/transpose_1" -> "430 bert/encoder/layer_0/attention/self/MatMul__306"  [label="[]", style=solid];
"430 bert/encoder/layer_0/attention/self/MatMul__306" -> "431 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"431 bert/encoder/layer_0/attention/self/MatMul" -> "432 bert/encoder/layer_0/attention/self/Mul"  [label="[]", style=solid];
"432 bert/encoder/layer_0/attention/self/Mul" -> "433 bert/encoder/layer_0/attention/self/add"  [label="[]", style=solid];
"433 bert/encoder/layer_0/attention/self/add" -> "434 bert/encoder/layer_0/attention/self/Softmax"  [label="[]", style=solid];
"434 bert/encoder/layer_0/attention/self/Softmax" -> "435 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"435 bert/encoder/layer_0/attention/self/MatMul_1" -> "436 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"436 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "437 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"437 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "438 bert/encoder/layer_0/attention/self/transpose_3"  [label="[]", style=solid];
"438 bert/encoder/layer_0/attention/self/transpose_3" -> "439 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[]", style=solid];
"439 bert/encoder/layer_0/attention/self/Reshape_3" -> "442 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[]", style=solid];
"440 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "441 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"441 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "442 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"442 bert/encoder/layer_0/attention/output/dense/MatMul" -> "443 bert/encoder/layer_0/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"443 bert/encoder/layer_0/attention/output/dense/BiasAdd" -> "444 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"444 bert/encoder/layer_0/attention/output/add" -> "445 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"444 bert/encoder/layer_0/attention/output/add" -> "447 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"444 bert/encoder/layer_0/attention/output/add" -> "456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"445 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "446 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"445 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"446 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" -> "447 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"447 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "448 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" -> "449 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" -> "450 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"450 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"451 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" -> "452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311"  [label="[]", style=solid];
"452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" -> "453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" -> "455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" -> "457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" -> "457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "458 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "478 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"458 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "459 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"459 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "462 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[]", style=solid];
"460 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "461 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"461 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "462 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"462 bert/encoder/layer_0/intermediate/dense/MatMul" -> "463 bert/encoder/layer_0/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"463 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "464 bert/encoder/layer_0/intermediate/dense/Pow"  [label="[]", style=solid];
"463 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "466 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"463 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "471 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"464 bert/encoder/layer_0/intermediate/dense/Pow" -> "465 bert/encoder/layer_0/intermediate/dense/mul"  [label="[]", style=solid];
"465 bert/encoder/layer_0/intermediate/dense/mul" -> "466 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"466 bert/encoder/layer_0/intermediate/dense/add" -> "467 bert/encoder/layer_0/intermediate/dense/mul_1"  [label="[]", style=solid];
"467 bert/encoder/layer_0/intermediate/dense/mul_1" -> "468 bert/encoder/layer_0/intermediate/dense/Tanh"  [label="[]", style=solid];
"468 bert/encoder/layer_0/intermediate/dense/Tanh" -> "469 bert/encoder/layer_0/intermediate/dense/add_1"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/add_1" -> "470 bert/encoder/layer_0/intermediate/dense/mul_2"  [label="[]", style=solid];
"470 bert/encoder/layer_0/intermediate/dense/mul_2" -> "471 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"471 bert/encoder/layer_0/intermediate/dense/mul_3" -> "472 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"472 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "473 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"473 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "476 bert/encoder/layer_0/output/dense/MatMul"  [label="[]", style=solid];
"474 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "475 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"475 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "476 bert/encoder/layer_0/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"476 bert/encoder/layer_0/output/dense/MatMul" -> "477 bert/encoder/layer_0/output/dense/BiasAdd"  [label="[]", style=solid];
"477 bert/encoder/layer_0/output/dense/BiasAdd" -> "478 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"478 bert/encoder/layer_0/output/add" -> "479 bert/encoder/layer_0/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"478 bert/encoder/layer_0/output/add" -> "481 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"478 bert/encoder/layer_0/output/add" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"479 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "480 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"479 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "488 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"480 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" -> "481 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"481 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "482 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313"  [label="[]", style=solid];
"482 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" -> "483 bert/encoder/layer_0/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"483 bert/encoder/layer_0/output/LayerNorm/moments/variance" -> "484 bert/encoder/layer_0/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" -> "485 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"485 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" -> "486 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315"  [label="[]", style=solid];
"486 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" -> "487 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"487 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "488 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"487 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" -> "489 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" -> "491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" -> "491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "534 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "514 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[]", style=solid];
"494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "506 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[]", style=solid];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "500 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[]", style=solid];
"498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "500 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"500 bert/encoder/layer_1/attention/self/value/MatMul" -> "501 bert/encoder/layer_1/attention/self/value/BiasAdd"  [label="[]", style=solid];
"501 bert/encoder/layer_1/attention/self/value/BiasAdd" -> "502 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[]", style=solid];
"502 bert/encoder/layer_1/attention/self/Reshape_2" -> "503 bert/encoder/layer_1/attention/self/transpose_2"  [label="[]", style=solid];
"503 bert/encoder/layer_1/attention/self/transpose_2" -> "525 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"504 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "505 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"505 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "506 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"506 bert/encoder/layer_1/attention/self/query/MatMul" -> "507 bert/encoder/layer_1/attention/self/query/BiasAdd"  [label="[]", style=solid];
"507 bert/encoder/layer_1/attention/self/query/BiasAdd" -> "508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "510 bert/encoder/layer_1/attention/self/Reshape"  [label="[]", style=solid];
"510 bert/encoder/layer_1/attention/self/Reshape" -> "511 bert/encoder/layer_1/attention/self/transpose"  [label="[]", style=solid];
"511 bert/encoder/layer_1/attention/self/transpose" -> "521 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "513 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "514 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"514 bert/encoder/layer_1/attention/self/key/MatMul" -> "515 bert/encoder/layer_1/attention/self/key/BiasAdd"  [label="[]", style=solid];
"515 bert/encoder/layer_1/attention/self/key/BiasAdd" -> "516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "518 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[]", style=solid];
"518 bert/encoder/layer_1/attention/self/Reshape_1" -> "519 bert/encoder/layer_1/attention/self/transpose_1"  [label="[]", style=solid];
"519 bert/encoder/layer_1/attention/self/transpose_1" -> "520 bert/encoder/layer_1/attention/self/MatMul__320"  [label="[]", style=solid];
"520 bert/encoder/layer_1/attention/self/MatMul__320" -> "521 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"521 bert/encoder/layer_1/attention/self/MatMul" -> "522 bert/encoder/layer_1/attention/self/Mul"  [label="[]", style=solid];
"522 bert/encoder/layer_1/attention/self/Mul" -> "523 bert/encoder/layer_1/attention/self/add"  [label="[]", style=solid];
"523 bert/encoder/layer_1/attention/self/add" -> "524 bert/encoder/layer_1/attention/self/Softmax"  [label="[]", style=solid];
"524 bert/encoder/layer_1/attention/self/Softmax" -> "525 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"525 bert/encoder/layer_1/attention/self/MatMul_1" -> "526 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"526 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "527 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"527 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "528 bert/encoder/layer_1/attention/self/transpose_3"  [label="[]", style=solid];
"528 bert/encoder/layer_1/attention/self/transpose_3" -> "529 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[]", style=solid];
"529 bert/encoder/layer_1/attention/self/Reshape_3" -> "532 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[]", style=solid];
"530 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "531 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"531 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "532 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"532 bert/encoder/layer_1/attention/output/dense/MatMul" -> "533 bert/encoder/layer_1/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"533 bert/encoder/layer_1/attention/output/dense/BiasAdd" -> "534 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"534 bert/encoder/layer_1/attention/output/add" -> "535 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"534 bert/encoder/layer_1/attention/output/add" -> "537 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"534 bert/encoder/layer_1/attention/output/add" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"535 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "536 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"535 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"536 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" -> "537 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"537 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "538 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323"  [label="[]", style=solid];
"538 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" -> "539 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" -> "540 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"540 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" -> "541 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"541 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" -> "542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" -> "543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" -> "545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" -> "547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" -> "547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "548 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "568 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"548 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "549 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"549 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "552 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[]", style=solid];
"550 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "551 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"551 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "552 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"552 bert/encoder/layer_1/intermediate/dense/MatMul" -> "553 bert/encoder/layer_1/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"553 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "554 bert/encoder/layer_1/intermediate/dense/Pow"  [label="[]", style=solid];
"553 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "556 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"553 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "561 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"554 bert/encoder/layer_1/intermediate/dense/Pow" -> "555 bert/encoder/layer_1/intermediate/dense/mul"  [label="[]", style=solid];
"555 bert/encoder/layer_1/intermediate/dense/mul" -> "556 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"556 bert/encoder/layer_1/intermediate/dense/add" -> "557 bert/encoder/layer_1/intermediate/dense/mul_1"  [label="[]", style=solid];
"557 bert/encoder/layer_1/intermediate/dense/mul_1" -> "558 bert/encoder/layer_1/intermediate/dense/Tanh"  [label="[]", style=solid];
"558 bert/encoder/layer_1/intermediate/dense/Tanh" -> "559 bert/encoder/layer_1/intermediate/dense/add_1"  [label="[]", style=solid];
"559 bert/encoder/layer_1/intermediate/dense/add_1" -> "560 bert/encoder/layer_1/intermediate/dense/mul_2"  [label="[]", style=solid];
"560 bert/encoder/layer_1/intermediate/dense/mul_2" -> "561 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"561 bert/encoder/layer_1/intermediate/dense/mul_3" -> "562 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"562 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "563 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"563 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "566 bert/encoder/layer_1/output/dense/MatMul"  [label="[]", style=solid];
"564 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "565 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"565 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "566 bert/encoder/layer_1/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"566 bert/encoder/layer_1/output/dense/MatMul" -> "567 bert/encoder/layer_1/output/dense/BiasAdd"  [label="[]", style=solid];
"567 bert/encoder/layer_1/output/dense/BiasAdd" -> "568 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"568 bert/encoder/layer_1/output/add" -> "569 bert/encoder/layer_1/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"568 bert/encoder/layer_1/output/add" -> "571 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"568 bert/encoder/layer_1/output/add" -> "580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"569 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "570 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"569 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "578 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"570 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" -> "571 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"571 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "572 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327"  [label="[]", style=solid];
"572 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" -> "573 bert/encoder/layer_1/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"573 bert/encoder/layer_1/output/LayerNorm/moments/variance" -> "574 bert/encoder/layer_1/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"574 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" -> "575 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"575 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" -> "576 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329"  [label="[]", style=solid];
"576 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" -> "577 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"577 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "578 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"577 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" -> "579 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" -> "581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" -> "581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "582 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "624 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"582 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "583 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"583 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "604 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[]", style=solid];
"584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "596 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[]", style=solid];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "590 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[]", style=solid];
"588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "590 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"590 bert/encoder/layer_2/attention/self/value/MatMul" -> "591 bert/encoder/layer_2/attention/self/value/BiasAdd"  [label="[]", style=solid];
"591 bert/encoder/layer_2/attention/self/value/BiasAdd" -> "592 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[]", style=solid];
"592 bert/encoder/layer_2/attention/self/Reshape_2" -> "593 bert/encoder/layer_2/attention/self/transpose_2"  [label="[]", style=solid];
"593 bert/encoder/layer_2/attention/self/transpose_2" -> "615 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"594 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "595 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"595 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "596 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"596 bert/encoder/layer_2/attention/self/query/MatMul" -> "597 bert/encoder/layer_2/attention/self/query/BiasAdd"  [label="[]", style=solid];
"597 bert/encoder/layer_2/attention/self/query/BiasAdd" -> "598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "600 bert/encoder/layer_2/attention/self/Reshape"  [label="[]", style=solid];
"600 bert/encoder/layer_2/attention/self/Reshape" -> "601 bert/encoder/layer_2/attention/self/transpose"  [label="[]", style=solid];
"601 bert/encoder/layer_2/attention/self/transpose" -> "611 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"602 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "603 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"603 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "604 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"604 bert/encoder/layer_2/attention/self/key/MatMul" -> "605 bert/encoder/layer_2/attention/self/key/BiasAdd"  [label="[]", style=solid];
"605 bert/encoder/layer_2/attention/self/key/BiasAdd" -> "606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "608 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[]", style=solid];
"608 bert/encoder/layer_2/attention/self/Reshape_1" -> "609 bert/encoder/layer_2/attention/self/transpose_1"  [label="[]", style=solid];
"609 bert/encoder/layer_2/attention/self/transpose_1" -> "610 bert/encoder/layer_2/attention/self/MatMul__334"  [label="[]", style=solid];
"610 bert/encoder/layer_2/attention/self/MatMul__334" -> "611 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"611 bert/encoder/layer_2/attention/self/MatMul" -> "612 bert/encoder/layer_2/attention/self/Mul"  [label="[]", style=solid];
"612 bert/encoder/layer_2/attention/self/Mul" -> "613 bert/encoder/layer_2/attention/self/add"  [label="[]", style=solid];
"613 bert/encoder/layer_2/attention/self/add" -> "614 bert/encoder/layer_2/attention/self/Softmax"  [label="[]", style=solid];
"614 bert/encoder/layer_2/attention/self/Softmax" -> "615 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"615 bert/encoder/layer_2/attention/self/MatMul_1" -> "616 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"616 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "617 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"617 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "618 bert/encoder/layer_2/attention/self/transpose_3"  [label="[]", style=solid];
"618 bert/encoder/layer_2/attention/self/transpose_3" -> "619 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[]", style=solid];
"619 bert/encoder/layer_2/attention/self/Reshape_3" -> "622 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[]", style=solid];
"620 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "621 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"621 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "622 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"622 bert/encoder/layer_2/attention/output/dense/MatMul" -> "623 bert/encoder/layer_2/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"623 bert/encoder/layer_2/attention/output/dense/BiasAdd" -> "624 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"624 bert/encoder/layer_2/attention/output/add" -> "625 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"624 bert/encoder/layer_2/attention/output/add" -> "627 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"624 bert/encoder/layer_2/attention/output/add" -> "636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"625 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "626 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"625 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"626 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" -> "627 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"627 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "628 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337"  [label="[]", style=solid];
"628 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" -> "629 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" -> "630 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"630 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" -> "631 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"631 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" -> "632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339"  [label="[]", style=solid];
"632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" -> "633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" -> "635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" -> "637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" -> "637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "638 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "658 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"638 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "639 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"639 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "642 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[]", style=solid];
"640 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "641 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"641 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "642 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"642 bert/encoder/layer_2/intermediate/dense/MatMul" -> "643 bert/encoder/layer_2/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"643 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "644 bert/encoder/layer_2/intermediate/dense/Pow"  [label="[]", style=solid];
"643 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "646 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"643 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "651 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"644 bert/encoder/layer_2/intermediate/dense/Pow" -> "645 bert/encoder/layer_2/intermediate/dense/mul"  [label="[]", style=solid];
"645 bert/encoder/layer_2/intermediate/dense/mul" -> "646 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"646 bert/encoder/layer_2/intermediate/dense/add" -> "647 bert/encoder/layer_2/intermediate/dense/mul_1"  [label="[]", style=solid];
"647 bert/encoder/layer_2/intermediate/dense/mul_1" -> "648 bert/encoder/layer_2/intermediate/dense/Tanh"  [label="[]", style=solid];
"648 bert/encoder/layer_2/intermediate/dense/Tanh" -> "649 bert/encoder/layer_2/intermediate/dense/add_1"  [label="[]", style=solid];
"649 bert/encoder/layer_2/intermediate/dense/add_1" -> "650 bert/encoder/layer_2/intermediate/dense/mul_2"  [label="[]", style=solid];
"650 bert/encoder/layer_2/intermediate/dense/mul_2" -> "651 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"651 bert/encoder/layer_2/intermediate/dense/mul_3" -> "652 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"652 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "653 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"653 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "656 bert/encoder/layer_2/output/dense/MatMul"  [label="[]", style=solid];
"654 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "655 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"655 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "656 bert/encoder/layer_2/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"656 bert/encoder/layer_2/output/dense/MatMul" -> "657 bert/encoder/layer_2/output/dense/BiasAdd"  [label="[]", style=solid];
"657 bert/encoder/layer_2/output/dense/BiasAdd" -> "658 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"658 bert/encoder/layer_2/output/add" -> "659 bert/encoder/layer_2/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"658 bert/encoder/layer_2/output/add" -> "661 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"658 bert/encoder/layer_2/output/add" -> "670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"659 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "660 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"659 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "668 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"660 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" -> "661 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"661 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "662 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341"  [label="[]", style=solid];
"662 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" -> "663 bert/encoder/layer_2/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"663 bert/encoder/layer_2/output/LayerNorm/moments/variance" -> "664 bert/encoder/layer_2/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"664 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" -> "665 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"665 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" -> "666 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343"  [label="[]", style=solid];
"666 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" -> "667 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"667 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "668 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"667 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" -> "669 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" -> "671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" -> "671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "672 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "714 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"672 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "673 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"673 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "694 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[]", style=solid];
"674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "686 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[]", style=solid];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "680 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[]", style=solid];
"678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "680 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"680 bert/encoder/layer_3/attention/self/value/MatMul" -> "681 bert/encoder/layer_3/attention/self/value/BiasAdd"  [label="[]", style=solid];
"681 bert/encoder/layer_3/attention/self/value/BiasAdd" -> "682 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[]", style=solid];
"682 bert/encoder/layer_3/attention/self/Reshape_2" -> "683 bert/encoder/layer_3/attention/self/transpose_2"  [label="[]", style=solid];
"683 bert/encoder/layer_3/attention/self/transpose_2" -> "705 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"684 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "685 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"685 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "686 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"686 bert/encoder/layer_3/attention/self/query/MatMul" -> "687 bert/encoder/layer_3/attention/self/query/BiasAdd"  [label="[]", style=solid];
"687 bert/encoder/layer_3/attention/self/query/BiasAdd" -> "688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "690 bert/encoder/layer_3/attention/self/Reshape"  [label="[]", style=solid];
"690 bert/encoder/layer_3/attention/self/Reshape" -> "691 bert/encoder/layer_3/attention/self/transpose"  [label="[]", style=solid];
"691 bert/encoder/layer_3/attention/self/transpose" -> "701 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"692 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "693 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"693 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "694 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"694 bert/encoder/layer_3/attention/self/key/MatMul" -> "695 bert/encoder/layer_3/attention/self/key/BiasAdd"  [label="[]", style=solid];
"695 bert/encoder/layer_3/attention/self/key/BiasAdd" -> "696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "698 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[]", style=solid];
"698 bert/encoder/layer_3/attention/self/Reshape_1" -> "699 bert/encoder/layer_3/attention/self/transpose_1"  [label="[]", style=solid];
"699 bert/encoder/layer_3/attention/self/transpose_1" -> "700 bert/encoder/layer_3/attention/self/MatMul__348"  [label="[]", style=solid];
"700 bert/encoder/layer_3/attention/self/MatMul__348" -> "701 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"701 bert/encoder/layer_3/attention/self/MatMul" -> "702 bert/encoder/layer_3/attention/self/Mul"  [label="[]", style=solid];
"702 bert/encoder/layer_3/attention/self/Mul" -> "703 bert/encoder/layer_3/attention/self/add"  [label="[]", style=solid];
"703 bert/encoder/layer_3/attention/self/add" -> "704 bert/encoder/layer_3/attention/self/Softmax"  [label="[]", style=solid];
"704 bert/encoder/layer_3/attention/self/Softmax" -> "705 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"705 bert/encoder/layer_3/attention/self/MatMul_1" -> "706 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"706 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "707 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"707 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "708 bert/encoder/layer_3/attention/self/transpose_3"  [label="[]", style=solid];
"708 bert/encoder/layer_3/attention/self/transpose_3" -> "709 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[]", style=solid];
"709 bert/encoder/layer_3/attention/self/Reshape_3" -> "712 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[]", style=solid];
"710 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "711 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"711 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "712 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"712 bert/encoder/layer_3/attention/output/dense/MatMul" -> "713 bert/encoder/layer_3/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"713 bert/encoder/layer_3/attention/output/dense/BiasAdd" -> "714 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"714 bert/encoder/layer_3/attention/output/add" -> "715 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"714 bert/encoder/layer_3/attention/output/add" -> "717 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"714 bert/encoder/layer_3/attention/output/add" -> "726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"715 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "716 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"715 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"716 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" -> "717 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"717 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "718 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" -> "719 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" -> "720 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"720 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" -> "721 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"721 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" -> "722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353"  [label="[]", style=solid];
"722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" -> "723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" -> "725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" -> "727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" -> "727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "728 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "748 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"728 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "729 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"729 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "732 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[]", style=solid];
"730 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "731 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"731 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "732 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"732 bert/encoder/layer_3/intermediate/dense/MatMul" -> "733 bert/encoder/layer_3/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"733 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "734 bert/encoder/layer_3/intermediate/dense/Pow"  [label="[]", style=solid];
"733 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "736 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"733 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "741 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"734 bert/encoder/layer_3/intermediate/dense/Pow" -> "735 bert/encoder/layer_3/intermediate/dense/mul"  [label="[]", style=solid];
"735 bert/encoder/layer_3/intermediate/dense/mul" -> "736 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"736 bert/encoder/layer_3/intermediate/dense/add" -> "737 bert/encoder/layer_3/intermediate/dense/mul_1"  [label="[]", style=solid];
"737 bert/encoder/layer_3/intermediate/dense/mul_1" -> "738 bert/encoder/layer_3/intermediate/dense/Tanh"  [label="[]", style=solid];
"738 bert/encoder/layer_3/intermediate/dense/Tanh" -> "739 bert/encoder/layer_3/intermediate/dense/add_1"  [label="[]", style=solid];
"739 bert/encoder/layer_3/intermediate/dense/add_1" -> "740 bert/encoder/layer_3/intermediate/dense/mul_2"  [label="[]", style=solid];
"740 bert/encoder/layer_3/intermediate/dense/mul_2" -> "741 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"741 bert/encoder/layer_3/intermediate/dense/mul_3" -> "742 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"742 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "743 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"743 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "746 bert/encoder/layer_3/output/dense/MatMul"  [label="[]", style=solid];
"744 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "745 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"745 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "746 bert/encoder/layer_3/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"746 bert/encoder/layer_3/output/dense/MatMul" -> "747 bert/encoder/layer_3/output/dense/BiasAdd"  [label="[]", style=solid];
"747 bert/encoder/layer_3/output/dense/BiasAdd" -> "748 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"748 bert/encoder/layer_3/output/add" -> "749 bert/encoder/layer_3/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"748 bert/encoder/layer_3/output/add" -> "751 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"748 bert/encoder/layer_3/output/add" -> "760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"749 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "750 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"749 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "758 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"750 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" -> "751 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"751 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "752 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355"  [label="[]", style=solid];
"752 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" -> "753 bert/encoder/layer_3/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"753 bert/encoder/layer_3/output/LayerNorm/moments/variance" -> "754 bert/encoder/layer_3/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"754 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" -> "755 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"755 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" -> "756 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357"  [label="[]", style=solid];
"756 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" -> "757 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"757 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "758 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"757 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" -> "759 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" -> "761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" -> "761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "762 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "804 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"762 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "763 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"763 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "784 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[]", style=solid];
"764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "776 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[]", style=solid];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "770 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[]", style=solid];
"768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "770 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"770 bert/encoder/layer_4/attention/self/value/MatMul" -> "771 bert/encoder/layer_4/attention/self/value/BiasAdd"  [label="[]", style=solid];
"771 bert/encoder/layer_4/attention/self/value/BiasAdd" -> "772 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[]", style=solid];
"772 bert/encoder/layer_4/attention/self/Reshape_2" -> "773 bert/encoder/layer_4/attention/self/transpose_2"  [label="[]", style=solid];
"773 bert/encoder/layer_4/attention/self/transpose_2" -> "795 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"774 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "775 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"775 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "776 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"776 bert/encoder/layer_4/attention/self/query/MatMul" -> "777 bert/encoder/layer_4/attention/self/query/BiasAdd"  [label="[]", style=solid];
"777 bert/encoder/layer_4/attention/self/query/BiasAdd" -> "778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "780 bert/encoder/layer_4/attention/self/Reshape"  [label="[]", style=solid];
"780 bert/encoder/layer_4/attention/self/Reshape" -> "781 bert/encoder/layer_4/attention/self/transpose"  [label="[]", style=solid];
"781 bert/encoder/layer_4/attention/self/transpose" -> "791 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"782 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "783 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"783 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "784 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"784 bert/encoder/layer_4/attention/self/key/MatMul" -> "785 bert/encoder/layer_4/attention/self/key/BiasAdd"  [label="[]", style=solid];
"785 bert/encoder/layer_4/attention/self/key/BiasAdd" -> "786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "788 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[]", style=solid];
"788 bert/encoder/layer_4/attention/self/Reshape_1" -> "789 bert/encoder/layer_4/attention/self/transpose_1"  [label="[]", style=solid];
"789 bert/encoder/layer_4/attention/self/transpose_1" -> "790 bert/encoder/layer_4/attention/self/MatMul__362"  [label="[]", style=solid];
"790 bert/encoder/layer_4/attention/self/MatMul__362" -> "791 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"791 bert/encoder/layer_4/attention/self/MatMul" -> "792 bert/encoder/layer_4/attention/self/Mul"  [label="[]", style=solid];
"792 bert/encoder/layer_4/attention/self/Mul" -> "793 bert/encoder/layer_4/attention/self/add"  [label="[]", style=solid];
"793 bert/encoder/layer_4/attention/self/add" -> "794 bert/encoder/layer_4/attention/self/Softmax"  [label="[]", style=solid];
"794 bert/encoder/layer_4/attention/self/Softmax" -> "795 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"795 bert/encoder/layer_4/attention/self/MatMul_1" -> "796 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"796 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "797 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"797 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "798 bert/encoder/layer_4/attention/self/transpose_3"  [label="[]", style=solid];
"798 bert/encoder/layer_4/attention/self/transpose_3" -> "799 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[]", style=solid];
"799 bert/encoder/layer_4/attention/self/Reshape_3" -> "802 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[]", style=solid];
"800 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "801 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"801 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "802 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"802 bert/encoder/layer_4/attention/output/dense/MatMul" -> "803 bert/encoder/layer_4/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"803 bert/encoder/layer_4/attention/output/dense/BiasAdd" -> "804 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"804 bert/encoder/layer_4/attention/output/add" -> "805 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"804 bert/encoder/layer_4/attention/output/add" -> "807 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"804 bert/encoder/layer_4/attention/output/add" -> "816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"805 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "806 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"805 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"806 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" -> "807 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"807 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "808 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" -> "809 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" -> "810 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"810 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" -> "811 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"811 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" -> "812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367"  [label="[]", style=solid];
"812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" -> "813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" -> "815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" -> "817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" -> "817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "818 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "838 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"818 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "819 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"819 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "822 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[]", style=solid];
"820 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "821 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"821 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "822 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"822 bert/encoder/layer_4/intermediate/dense/MatMul" -> "823 bert/encoder/layer_4/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"823 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "824 bert/encoder/layer_4/intermediate/dense/Pow"  [label="[]", style=solid];
"823 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "826 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"823 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "831 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"824 bert/encoder/layer_4/intermediate/dense/Pow" -> "825 bert/encoder/layer_4/intermediate/dense/mul"  [label="[]", style=solid];
"825 bert/encoder/layer_4/intermediate/dense/mul" -> "826 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"826 bert/encoder/layer_4/intermediate/dense/add" -> "827 bert/encoder/layer_4/intermediate/dense/mul_1"  [label="[]", style=solid];
"827 bert/encoder/layer_4/intermediate/dense/mul_1" -> "828 bert/encoder/layer_4/intermediate/dense/Tanh"  [label="[]", style=solid];
"828 bert/encoder/layer_4/intermediate/dense/Tanh" -> "829 bert/encoder/layer_4/intermediate/dense/add_1"  [label="[]", style=solid];
"829 bert/encoder/layer_4/intermediate/dense/add_1" -> "830 bert/encoder/layer_4/intermediate/dense/mul_2"  [label="[]", style=solid];
"830 bert/encoder/layer_4/intermediate/dense/mul_2" -> "831 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"831 bert/encoder/layer_4/intermediate/dense/mul_3" -> "832 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"832 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "833 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"833 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "836 bert/encoder/layer_4/output/dense/MatMul"  [label="[]", style=solid];
"834 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "835 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"835 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "836 bert/encoder/layer_4/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"836 bert/encoder/layer_4/output/dense/MatMul" -> "837 bert/encoder/layer_4/output/dense/BiasAdd"  [label="[]", style=solid];
"837 bert/encoder/layer_4/output/dense/BiasAdd" -> "838 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"838 bert/encoder/layer_4/output/add" -> "839 bert/encoder/layer_4/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"838 bert/encoder/layer_4/output/add" -> "841 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"838 bert/encoder/layer_4/output/add" -> "850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"839 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "840 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"839 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "848 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"840 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" -> "841 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"841 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "842 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369"  [label="[]", style=solid];
"842 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" -> "843 bert/encoder/layer_4/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"843 bert/encoder/layer_4/output/LayerNorm/moments/variance" -> "844 bert/encoder/layer_4/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"844 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" -> "845 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"845 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" -> "846 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371"  [label="[]", style=solid];
"846 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" -> "847 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"847 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "848 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"847 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" -> "849 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" -> "851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" -> "851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "852 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "894 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"852 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "853 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"853 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "874 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[]", style=solid];
"854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "866 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[]", style=solid];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "860 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[]", style=solid];
"858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "860 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"860 bert/encoder/layer_5/attention/self/value/MatMul" -> "861 bert/encoder/layer_5/attention/self/value/BiasAdd"  [label="[]", style=solid];
"861 bert/encoder/layer_5/attention/self/value/BiasAdd" -> "862 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[]", style=solid];
"862 bert/encoder/layer_5/attention/self/Reshape_2" -> "863 bert/encoder/layer_5/attention/self/transpose_2"  [label="[]", style=solid];
"863 bert/encoder/layer_5/attention/self/transpose_2" -> "885 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"864 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "865 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"865 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "866 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"866 bert/encoder/layer_5/attention/self/query/MatMul" -> "867 bert/encoder/layer_5/attention/self/query/BiasAdd"  [label="[]", style=solid];
"867 bert/encoder/layer_5/attention/self/query/BiasAdd" -> "868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "870 bert/encoder/layer_5/attention/self/Reshape"  [label="[]", style=solid];
"870 bert/encoder/layer_5/attention/self/Reshape" -> "871 bert/encoder/layer_5/attention/self/transpose"  [label="[]", style=solid];
"871 bert/encoder/layer_5/attention/self/transpose" -> "881 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"872 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "873 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"873 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "874 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"874 bert/encoder/layer_5/attention/self/key/MatMul" -> "875 bert/encoder/layer_5/attention/self/key/BiasAdd"  [label="[]", style=solid];
"875 bert/encoder/layer_5/attention/self/key/BiasAdd" -> "876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "878 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[]", style=solid];
"878 bert/encoder/layer_5/attention/self/Reshape_1" -> "879 bert/encoder/layer_5/attention/self/transpose_1"  [label="[]", style=solid];
"879 bert/encoder/layer_5/attention/self/transpose_1" -> "880 bert/encoder/layer_5/attention/self/MatMul__376"  [label="[]", style=solid];
"880 bert/encoder/layer_5/attention/self/MatMul__376" -> "881 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"881 bert/encoder/layer_5/attention/self/MatMul" -> "882 bert/encoder/layer_5/attention/self/Mul"  [label="[]", style=solid];
"882 bert/encoder/layer_5/attention/self/Mul" -> "883 bert/encoder/layer_5/attention/self/add"  [label="[]", style=solid];
"883 bert/encoder/layer_5/attention/self/add" -> "884 bert/encoder/layer_5/attention/self/Softmax"  [label="[]", style=solid];
"884 bert/encoder/layer_5/attention/self/Softmax" -> "885 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"885 bert/encoder/layer_5/attention/self/MatMul_1" -> "886 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"886 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "887 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"887 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "888 bert/encoder/layer_5/attention/self/transpose_3"  [label="[]", style=solid];
"888 bert/encoder/layer_5/attention/self/transpose_3" -> "889 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[]", style=solid];
"889 bert/encoder/layer_5/attention/self/Reshape_3" -> "892 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[]", style=solid];
"890 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "891 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"891 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "892 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"892 bert/encoder/layer_5/attention/output/dense/MatMul" -> "893 bert/encoder/layer_5/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"893 bert/encoder/layer_5/attention/output/dense/BiasAdd" -> "894 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"894 bert/encoder/layer_5/attention/output/add" -> "895 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"894 bert/encoder/layer_5/attention/output/add" -> "897 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"894 bert/encoder/layer_5/attention/output/add" -> "906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"895 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "896 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"895 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"896 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" -> "897 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"897 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "898 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379"  [label="[]", style=solid];
"898 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" -> "899 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" -> "900 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"900 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" -> "901 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"901 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" -> "902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381"  [label="[]", style=solid];
"902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" -> "903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" -> "905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" -> "907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" -> "907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "908 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "928 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"908 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "909 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"909 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "912 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[]", style=solid];
"910 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "911 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"911 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "912 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"912 bert/encoder/layer_5/intermediate/dense/MatMul" -> "913 bert/encoder/layer_5/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"913 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "914 bert/encoder/layer_5/intermediate/dense/Pow"  [label="[]", style=solid];
"913 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "916 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"913 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "921 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"914 bert/encoder/layer_5/intermediate/dense/Pow" -> "915 bert/encoder/layer_5/intermediate/dense/mul"  [label="[]", style=solid];
"915 bert/encoder/layer_5/intermediate/dense/mul" -> "916 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"916 bert/encoder/layer_5/intermediate/dense/add" -> "917 bert/encoder/layer_5/intermediate/dense/mul_1"  [label="[]", style=solid];
"917 bert/encoder/layer_5/intermediate/dense/mul_1" -> "918 bert/encoder/layer_5/intermediate/dense/Tanh"  [label="[]", style=solid];
"918 bert/encoder/layer_5/intermediate/dense/Tanh" -> "919 bert/encoder/layer_5/intermediate/dense/add_1"  [label="[]", style=solid];
"919 bert/encoder/layer_5/intermediate/dense/add_1" -> "920 bert/encoder/layer_5/intermediate/dense/mul_2"  [label="[]", style=solid];
"920 bert/encoder/layer_5/intermediate/dense/mul_2" -> "921 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"921 bert/encoder/layer_5/intermediate/dense/mul_3" -> "922 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"922 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "923 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"923 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "926 bert/encoder/layer_5/output/dense/MatMul"  [label="[]", style=solid];
"924 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "925 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"925 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "926 bert/encoder/layer_5/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"926 bert/encoder/layer_5/output/dense/MatMul" -> "927 bert/encoder/layer_5/output/dense/BiasAdd"  [label="[]", style=solid];
"927 bert/encoder/layer_5/output/dense/BiasAdd" -> "928 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"928 bert/encoder/layer_5/output/add" -> "929 bert/encoder/layer_5/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"928 bert/encoder/layer_5/output/add" -> "931 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"928 bert/encoder/layer_5/output/add" -> "940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"929 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "930 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"929 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "938 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"930 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" -> "931 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"931 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "932 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383"  [label="[]", style=solid];
"932 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" -> "933 bert/encoder/layer_5/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"933 bert/encoder/layer_5/output/LayerNorm/moments/variance" -> "934 bert/encoder/layer_5/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"934 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" -> "935 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"935 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" -> "936 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385"  [label="[]", style=solid];
"936 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" -> "937 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"937 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "938 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"937 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" -> "939 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" -> "941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" -> "941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "942 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "984 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"942 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "943 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"943 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "964 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[]", style=solid];
"944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "956 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[]", style=solid];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "950 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[]", style=solid];
"948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "950 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"950 bert/encoder/layer_6/attention/self/value/MatMul" -> "951 bert/encoder/layer_6/attention/self/value/BiasAdd"  [label="[]", style=solid];
"951 bert/encoder/layer_6/attention/self/value/BiasAdd" -> "952 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[]", style=solid];
"952 bert/encoder/layer_6/attention/self/Reshape_2" -> "953 bert/encoder/layer_6/attention/self/transpose_2"  [label="[]", style=solid];
"953 bert/encoder/layer_6/attention/self/transpose_2" -> "975 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"954 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "955 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"955 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "956 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"956 bert/encoder/layer_6/attention/self/query/MatMul" -> "957 bert/encoder/layer_6/attention/self/query/BiasAdd"  [label="[]", style=solid];
"957 bert/encoder/layer_6/attention/self/query/BiasAdd" -> "958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "960 bert/encoder/layer_6/attention/self/Reshape"  [label="[]", style=solid];
"960 bert/encoder/layer_6/attention/self/Reshape" -> "961 bert/encoder/layer_6/attention/self/transpose"  [label="[]", style=solid];
"961 bert/encoder/layer_6/attention/self/transpose" -> "971 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"962 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "963 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"963 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "964 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"964 bert/encoder/layer_6/attention/self/key/MatMul" -> "965 bert/encoder/layer_6/attention/self/key/BiasAdd"  [label="[]", style=solid];
"965 bert/encoder/layer_6/attention/self/key/BiasAdd" -> "966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "968 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[]", style=solid];
"968 bert/encoder/layer_6/attention/self/Reshape_1" -> "969 bert/encoder/layer_6/attention/self/transpose_1"  [label="[]", style=solid];
"969 bert/encoder/layer_6/attention/self/transpose_1" -> "970 bert/encoder/layer_6/attention/self/MatMul__390"  [label="[]", style=solid];
"970 bert/encoder/layer_6/attention/self/MatMul__390" -> "971 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"971 bert/encoder/layer_6/attention/self/MatMul" -> "972 bert/encoder/layer_6/attention/self/Mul"  [label="[]", style=solid];
"972 bert/encoder/layer_6/attention/self/Mul" -> "973 bert/encoder/layer_6/attention/self/add"  [label="[]", style=solid];
"973 bert/encoder/layer_6/attention/self/add" -> "974 bert/encoder/layer_6/attention/self/Softmax"  [label="[]", style=solid];
"974 bert/encoder/layer_6/attention/self/Softmax" -> "975 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"975 bert/encoder/layer_6/attention/self/MatMul_1" -> "976 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"976 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "977 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"977 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "978 bert/encoder/layer_6/attention/self/transpose_3"  [label="[]", style=solid];
"978 bert/encoder/layer_6/attention/self/transpose_3" -> "979 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[]", style=solid];
"979 bert/encoder/layer_6/attention/self/Reshape_3" -> "982 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[]", style=solid];
"980 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "981 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"981 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "982 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"982 bert/encoder/layer_6/attention/output/dense/MatMul" -> "983 bert/encoder/layer_6/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"983 bert/encoder/layer_6/attention/output/dense/BiasAdd" -> "984 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"984 bert/encoder/layer_6/attention/output/add" -> "985 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"984 bert/encoder/layer_6/attention/output/add" -> "987 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"984 bert/encoder/layer_6/attention/output/add" -> "996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"985 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "986 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"985 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"986 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" -> "987 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"987 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "988 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" -> "989 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" -> "990 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"990 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" -> "991 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"991 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" -> "992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395"  [label="[]", style=solid];
"992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" -> "993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" -> "995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" -> "997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" -> "997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "998 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1018 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"998 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "999 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"999 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1002 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[]", style=solid];
"1000 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1001 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1001 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1002 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1002 bert/encoder/layer_6/intermediate/dense/MatMul" -> "1003 bert/encoder/layer_6/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1003 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1004 bert/encoder/layer_6/intermediate/dense/Pow"  [label="[]", style=solid];
"1003 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1006 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1003 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1011 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1004 bert/encoder/layer_6/intermediate/dense/Pow" -> "1005 bert/encoder/layer_6/intermediate/dense/mul"  [label="[]", style=solid];
"1005 bert/encoder/layer_6/intermediate/dense/mul" -> "1006 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1006 bert/encoder/layer_6/intermediate/dense/add" -> "1007 bert/encoder/layer_6/intermediate/dense/mul_1"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/intermediate/dense/mul_1" -> "1008 bert/encoder/layer_6/intermediate/dense/Tanh"  [label="[]", style=solid];
"1008 bert/encoder/layer_6/intermediate/dense/Tanh" -> "1009 bert/encoder/layer_6/intermediate/dense/add_1"  [label="[]", style=solid];
"1009 bert/encoder/layer_6/intermediate/dense/add_1" -> "1010 bert/encoder/layer_6/intermediate/dense/mul_2"  [label="[]", style=solid];
"1010 bert/encoder/layer_6/intermediate/dense/mul_2" -> "1011 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1011 bert/encoder/layer_6/intermediate/dense/mul_3" -> "1012 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1012 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1013 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1013 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1016 bert/encoder/layer_6/output/dense/MatMul"  [label="[]", style=solid];
"1014 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1015 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1015 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1016 bert/encoder/layer_6/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1016 bert/encoder/layer_6/output/dense/MatMul" -> "1017 bert/encoder/layer_6/output/dense/BiasAdd"  [label="[]", style=solid];
"1017 bert/encoder/layer_6/output/dense/BiasAdd" -> "1018 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1018 bert/encoder/layer_6/output/add" -> "1019 bert/encoder/layer_6/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1018 bert/encoder/layer_6/output/add" -> "1021 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1018 bert/encoder/layer_6/output/add" -> "1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1019 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1020 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1019 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1020 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" -> "1021 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1021 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1022 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" -> "1023 bert/encoder/layer_6/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/variance" -> "1024 bert/encoder/layer_6/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1024 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" -> "1025 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1025 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" -> "1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399"  [label="[]", style=solid];
"1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" -> "1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" -> "1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" -> "1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" -> "1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1032 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1074 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1032 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1033 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1033 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1054 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[]", style=solid];
"1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1046 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[]", style=solid];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1040 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[]", style=solid];
"1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1040 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1040 bert/encoder/layer_7/attention/self/value/MatMul" -> "1041 bert/encoder/layer_7/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1041 bert/encoder/layer_7/attention/self/value/BiasAdd" -> "1042 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[]", style=solid];
"1042 bert/encoder/layer_7/attention/self/Reshape_2" -> "1043 bert/encoder/layer_7/attention/self/transpose_2"  [label="[]", style=solid];
"1043 bert/encoder/layer_7/attention/self/transpose_2" -> "1065 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1044 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1045 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1045 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1046 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1046 bert/encoder/layer_7/attention/self/query/MatMul" -> "1047 bert/encoder/layer_7/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1047 bert/encoder/layer_7/attention/self/query/BiasAdd" -> "1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1050 bert/encoder/layer_7/attention/self/Reshape"  [label="[]", style=solid];
"1050 bert/encoder/layer_7/attention/self/Reshape" -> "1051 bert/encoder/layer_7/attention/self/transpose"  [label="[]", style=solid];
"1051 bert/encoder/layer_7/attention/self/transpose" -> "1061 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1052 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1053 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1053 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1054 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1054 bert/encoder/layer_7/attention/self/key/MatMul" -> "1055 bert/encoder/layer_7/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1055 bert/encoder/layer_7/attention/self/key/BiasAdd" -> "1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1058 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[]", style=solid];
"1058 bert/encoder/layer_7/attention/self/Reshape_1" -> "1059 bert/encoder/layer_7/attention/self/transpose_1"  [label="[]", style=solid];
"1059 bert/encoder/layer_7/attention/self/transpose_1" -> "1060 bert/encoder/layer_7/attention/self/MatMul__404"  [label="[]", style=solid];
"1060 bert/encoder/layer_7/attention/self/MatMul__404" -> "1061 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1061 bert/encoder/layer_7/attention/self/MatMul" -> "1062 bert/encoder/layer_7/attention/self/Mul"  [label="[]", style=solid];
"1062 bert/encoder/layer_7/attention/self/Mul" -> "1063 bert/encoder/layer_7/attention/self/add"  [label="[]", style=solid];
"1063 bert/encoder/layer_7/attention/self/add" -> "1064 bert/encoder/layer_7/attention/self/Softmax"  [label="[]", style=solid];
"1064 bert/encoder/layer_7/attention/self/Softmax" -> "1065 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1065 bert/encoder/layer_7/attention/self/MatMul_1" -> "1066 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1066 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1067 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1067 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1068 bert/encoder/layer_7/attention/self/transpose_3"  [label="[]", style=solid];
"1068 bert/encoder/layer_7/attention/self/transpose_3" -> "1069 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[]", style=solid];
"1069 bert/encoder/layer_7/attention/self/Reshape_3" -> "1072 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[]", style=solid];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1071 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1072 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1072 bert/encoder/layer_7/attention/output/dense/MatMul" -> "1073 bert/encoder/layer_7/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1073 bert/encoder/layer_7/attention/output/dense/BiasAdd" -> "1074 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1074 bert/encoder/layer_7/attention/output/add" -> "1075 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1074 bert/encoder/layer_7/attention/output/add" -> "1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1074 bert/encoder/layer_7/attention/output/add" -> "1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1075 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1076 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1075 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1076 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" -> "1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407"  [label="[]", style=solid];
"1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" -> "1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" -> "1080 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" -> "1081 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409"  [label="[]", style=solid];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" -> "1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" -> "1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" -> "1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" -> "1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1088 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1108 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1088 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1089 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1089 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1092 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[]", style=solid];
"1090 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1091 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1091 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1092 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1092 bert/encoder/layer_7/intermediate/dense/MatMul" -> "1093 bert/encoder/layer_7/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1093 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1094 bert/encoder/layer_7/intermediate/dense/Pow"  [label="[]", style=solid];
"1093 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1096 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1093 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1101 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1094 bert/encoder/layer_7/intermediate/dense/Pow" -> "1095 bert/encoder/layer_7/intermediate/dense/mul"  [label="[]", style=solid];
"1095 bert/encoder/layer_7/intermediate/dense/mul" -> "1096 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1096 bert/encoder/layer_7/intermediate/dense/add" -> "1097 bert/encoder/layer_7/intermediate/dense/mul_1"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/intermediate/dense/mul_1" -> "1098 bert/encoder/layer_7/intermediate/dense/Tanh"  [label="[]", style=solid];
"1098 bert/encoder/layer_7/intermediate/dense/Tanh" -> "1099 bert/encoder/layer_7/intermediate/dense/add_1"  [label="[]", style=solid];
"1099 bert/encoder/layer_7/intermediate/dense/add_1" -> "1100 bert/encoder/layer_7/intermediate/dense/mul_2"  [label="[]", style=solid];
"1100 bert/encoder/layer_7/intermediate/dense/mul_2" -> "1101 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1101 bert/encoder/layer_7/intermediate/dense/mul_3" -> "1102 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1102 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1103 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1103 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1106 bert/encoder/layer_7/output/dense/MatMul"  [label="[]", style=solid];
"1104 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1105 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1105 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1106 bert/encoder/layer_7/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1106 bert/encoder/layer_7/output/dense/MatMul" -> "1107 bert/encoder/layer_7/output/dense/BiasAdd"  [label="[]", style=solid];
"1107 bert/encoder/layer_7/output/dense/BiasAdd" -> "1108 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1108 bert/encoder/layer_7/output/add" -> "1109 bert/encoder/layer_7/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1108 bert/encoder/layer_7/output/add" -> "1111 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1108 bert/encoder/layer_7/output/add" -> "1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1109 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1110 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1109 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1110 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" -> "1111 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1111 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1112 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" -> "1113 bert/encoder/layer_7/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/variance" -> "1114 bert/encoder/layer_7/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1114 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" -> "1115 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1115 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" -> "1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413"  [label="[]", style=solid];
"1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" -> "1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" -> "1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" -> "1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" -> "1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1122 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1164 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1122 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1123 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1123 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1144 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[]", style=solid];
"1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1136 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[]", style=solid];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1130 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[]", style=solid];
"1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1130 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1130 bert/encoder/layer_8/attention/self/value/MatMul" -> "1131 bert/encoder/layer_8/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1131 bert/encoder/layer_8/attention/self/value/BiasAdd" -> "1132 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[]", style=solid];
"1132 bert/encoder/layer_8/attention/self/Reshape_2" -> "1133 bert/encoder/layer_8/attention/self/transpose_2"  [label="[]", style=solid];
"1133 bert/encoder/layer_8/attention/self/transpose_2" -> "1155 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1134 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1135 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1135 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1136 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1136 bert/encoder/layer_8/attention/self/query/MatMul" -> "1137 bert/encoder/layer_8/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1137 bert/encoder/layer_8/attention/self/query/BiasAdd" -> "1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1140 bert/encoder/layer_8/attention/self/Reshape"  [label="[]", style=solid];
"1140 bert/encoder/layer_8/attention/self/Reshape" -> "1141 bert/encoder/layer_8/attention/self/transpose"  [label="[]", style=solid];
"1141 bert/encoder/layer_8/attention/self/transpose" -> "1151 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1142 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1143 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1143 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1144 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1144 bert/encoder/layer_8/attention/self/key/MatMul" -> "1145 bert/encoder/layer_8/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1145 bert/encoder/layer_8/attention/self/key/BiasAdd" -> "1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1148 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[]", style=solid];
"1148 bert/encoder/layer_8/attention/self/Reshape_1" -> "1149 bert/encoder/layer_8/attention/self/transpose_1"  [label="[]", style=solid];
"1149 bert/encoder/layer_8/attention/self/transpose_1" -> "1150 bert/encoder/layer_8/attention/self/MatMul__418"  [label="[]", style=solid];
"1150 bert/encoder/layer_8/attention/self/MatMul__418" -> "1151 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1151 bert/encoder/layer_8/attention/self/MatMul" -> "1152 bert/encoder/layer_8/attention/self/Mul"  [label="[]", style=solid];
"1152 bert/encoder/layer_8/attention/self/Mul" -> "1153 bert/encoder/layer_8/attention/self/add"  [label="[]", style=solid];
"1153 bert/encoder/layer_8/attention/self/add" -> "1154 bert/encoder/layer_8/attention/self/Softmax"  [label="[]", style=solid];
"1154 bert/encoder/layer_8/attention/self/Softmax" -> "1155 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1155 bert/encoder/layer_8/attention/self/MatMul_1" -> "1156 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1156 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1157 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1157 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1158 bert/encoder/layer_8/attention/self/transpose_3"  [label="[]", style=solid];
"1158 bert/encoder/layer_8/attention/self/transpose_3" -> "1159 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[]", style=solid];
"1159 bert/encoder/layer_8/attention/self/Reshape_3" -> "1162 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[]", style=solid];
"1160 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1161 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1161 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1162 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1162 bert/encoder/layer_8/attention/output/dense/MatMul" -> "1163 bert/encoder/layer_8/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1163 bert/encoder/layer_8/attention/output/dense/BiasAdd" -> "1164 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1164 bert/encoder/layer_8/attention/output/add" -> "1165 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1164 bert/encoder/layer_8/attention/output/add" -> "1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1164 bert/encoder/layer_8/attention/output/add" -> "1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1165 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1166 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1165 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1166 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" -> "1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" -> "1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" -> "1170 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" -> "1171 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423"  [label="[]", style=solid];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" -> "1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" -> "1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" -> "1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" -> "1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1178 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1198 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1178 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1179 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1179 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1182 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[]", style=solid];
"1180 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1181 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1181 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1182 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1182 bert/encoder/layer_8/intermediate/dense/MatMul" -> "1183 bert/encoder/layer_8/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1183 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1184 bert/encoder/layer_8/intermediate/dense/Pow"  [label="[]", style=solid];
"1183 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1186 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1183 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1191 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1184 bert/encoder/layer_8/intermediate/dense/Pow" -> "1185 bert/encoder/layer_8/intermediate/dense/mul"  [label="[]", style=solid];
"1185 bert/encoder/layer_8/intermediate/dense/mul" -> "1186 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1186 bert/encoder/layer_8/intermediate/dense/add" -> "1187 bert/encoder/layer_8/intermediate/dense/mul_1"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/intermediate/dense/mul_1" -> "1188 bert/encoder/layer_8/intermediate/dense/Tanh"  [label="[]", style=solid];
"1188 bert/encoder/layer_8/intermediate/dense/Tanh" -> "1189 bert/encoder/layer_8/intermediate/dense/add_1"  [label="[]", style=solid];
"1189 bert/encoder/layer_8/intermediate/dense/add_1" -> "1190 bert/encoder/layer_8/intermediate/dense/mul_2"  [label="[]", style=solid];
"1190 bert/encoder/layer_8/intermediate/dense/mul_2" -> "1191 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1191 bert/encoder/layer_8/intermediate/dense/mul_3" -> "1192 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1192 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1193 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1193 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1196 bert/encoder/layer_8/output/dense/MatMul"  [label="[]", style=solid];
"1194 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1195 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1195 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1196 bert/encoder/layer_8/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1196 bert/encoder/layer_8/output/dense/MatMul" -> "1197 bert/encoder/layer_8/output/dense/BiasAdd"  [label="[]", style=solid];
"1197 bert/encoder/layer_8/output/dense/BiasAdd" -> "1198 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1198 bert/encoder/layer_8/output/add" -> "1199 bert/encoder/layer_8/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1198 bert/encoder/layer_8/output/add" -> "1201 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1198 bert/encoder/layer_8/output/add" -> "1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1199 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1200 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1199 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" -> "1201 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1202 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" -> "1203 bert/encoder/layer_8/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/variance" -> "1204 bert/encoder/layer_8/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1204 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" -> "1205 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1205 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" -> "1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427"  [label="[]", style=solid];
"1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" -> "1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" -> "1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" -> "1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" -> "1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1212 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1254 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1212 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1213 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1213 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1234 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[]", style=solid];
"1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1226 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[]", style=solid];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1220 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[]", style=solid];
"1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1220 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1220 bert/encoder/layer_9/attention/self/value/MatMul" -> "1221 bert/encoder/layer_9/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1221 bert/encoder/layer_9/attention/self/value/BiasAdd" -> "1222 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[]", style=solid];
"1222 bert/encoder/layer_9/attention/self/Reshape_2" -> "1223 bert/encoder/layer_9/attention/self/transpose_2"  [label="[]", style=solid];
"1223 bert/encoder/layer_9/attention/self/transpose_2" -> "1245 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1224 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1225 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1225 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1226 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1226 bert/encoder/layer_9/attention/self/query/MatMul" -> "1227 bert/encoder/layer_9/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1227 bert/encoder/layer_9/attention/self/query/BiasAdd" -> "1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1230 bert/encoder/layer_9/attention/self/Reshape"  [label="[]", style=solid];
"1230 bert/encoder/layer_9/attention/self/Reshape" -> "1231 bert/encoder/layer_9/attention/self/transpose"  [label="[]", style=solid];
"1231 bert/encoder/layer_9/attention/self/transpose" -> "1241 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1232 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1233 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1233 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1234 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1234 bert/encoder/layer_9/attention/self/key/MatMul" -> "1235 bert/encoder/layer_9/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1235 bert/encoder/layer_9/attention/self/key/BiasAdd" -> "1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1238 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[]", style=solid];
"1238 bert/encoder/layer_9/attention/self/Reshape_1" -> "1239 bert/encoder/layer_9/attention/self/transpose_1"  [label="[]", style=solid];
"1239 bert/encoder/layer_9/attention/self/transpose_1" -> "1240 bert/encoder/layer_9/attention/self/MatMul__432"  [label="[]", style=solid];
"1240 bert/encoder/layer_9/attention/self/MatMul__432" -> "1241 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1241 bert/encoder/layer_9/attention/self/MatMul" -> "1242 bert/encoder/layer_9/attention/self/Mul"  [label="[]", style=solid];
"1242 bert/encoder/layer_9/attention/self/Mul" -> "1243 bert/encoder/layer_9/attention/self/add"  [label="[]", style=solid];
"1243 bert/encoder/layer_9/attention/self/add" -> "1244 bert/encoder/layer_9/attention/self/Softmax"  [label="[]", style=solid];
"1244 bert/encoder/layer_9/attention/self/Softmax" -> "1245 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1245 bert/encoder/layer_9/attention/self/MatMul_1" -> "1246 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1246 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1247 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1247 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1248 bert/encoder/layer_9/attention/self/transpose_3"  [label="[]", style=solid];
"1248 bert/encoder/layer_9/attention/self/transpose_3" -> "1249 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[]", style=solid];
"1249 bert/encoder/layer_9/attention/self/Reshape_3" -> "1252 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[]", style=solid];
"1250 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1251 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1251 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1252 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1252 bert/encoder/layer_9/attention/output/dense/MatMul" -> "1253 bert/encoder/layer_9/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1253 bert/encoder/layer_9/attention/output/dense/BiasAdd" -> "1254 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1254 bert/encoder/layer_9/attention/output/add" -> "1255 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1254 bert/encoder/layer_9/attention/output/add" -> "1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1254 bert/encoder/layer_9/attention/output/add" -> "1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1255 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1256 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1255 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1256 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" -> "1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435"  [label="[]", style=solid];
"1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" -> "1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" -> "1260 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" -> "1261 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437"  [label="[]", style=solid];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" -> "1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" -> "1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" -> "1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" -> "1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1268 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1288 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1268 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1269 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1269 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1272 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[]", style=solid];
"1270 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1271 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1271 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1272 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1272 bert/encoder/layer_9/intermediate/dense/MatMul" -> "1273 bert/encoder/layer_9/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1273 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1274 bert/encoder/layer_9/intermediate/dense/Pow"  [label="[]", style=solid];
"1273 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1276 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1273 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1281 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1274 bert/encoder/layer_9/intermediate/dense/Pow" -> "1275 bert/encoder/layer_9/intermediate/dense/mul"  [label="[]", style=solid];
"1275 bert/encoder/layer_9/intermediate/dense/mul" -> "1276 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1276 bert/encoder/layer_9/intermediate/dense/add" -> "1277 bert/encoder/layer_9/intermediate/dense/mul_1"  [label="[]", style=solid];
"1277 bert/encoder/layer_9/intermediate/dense/mul_1" -> "1278 bert/encoder/layer_9/intermediate/dense/Tanh"  [label="[]", style=solid];
"1278 bert/encoder/layer_9/intermediate/dense/Tanh" -> "1279 bert/encoder/layer_9/intermediate/dense/add_1"  [label="[]", style=solid];
"1279 bert/encoder/layer_9/intermediate/dense/add_1" -> "1280 bert/encoder/layer_9/intermediate/dense/mul_2"  [label="[]", style=solid];
"1280 bert/encoder/layer_9/intermediate/dense/mul_2" -> "1281 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1281 bert/encoder/layer_9/intermediate/dense/mul_3" -> "1282 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1282 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1283 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1283 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1286 bert/encoder/layer_9/output/dense/MatMul"  [label="[]", style=solid];
"1284 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1285 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1285 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1286 bert/encoder/layer_9/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1286 bert/encoder/layer_9/output/dense/MatMul" -> "1287 bert/encoder/layer_9/output/dense/BiasAdd"  [label="[]", style=solid];
"1287 bert/encoder/layer_9/output/dense/BiasAdd" -> "1288 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1288 bert/encoder/layer_9/output/add" -> "1289 bert/encoder/layer_9/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1288 bert/encoder/layer_9/output/add" -> "1291 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1288 bert/encoder/layer_9/output/add" -> "1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1289 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1290 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1289 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1290 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" -> "1291 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1291 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1292 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439"  [label="[]", style=solid];
"1292 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" -> "1293 bert/encoder/layer_9/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/variance" -> "1294 bert/encoder/layer_9/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" -> "1295 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1295 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" -> "1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441"  [label="[]", style=solid];
"1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" -> "1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" -> "1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" -> "1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" -> "1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1302 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1344 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1302 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1303 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1303 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1324 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[]", style=solid];
"1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1316 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[]", style=solid];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1310 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[]", style=solid];
"1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1310 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1310 bert/encoder/layer_10/attention/self/value/MatMul" -> "1311 bert/encoder/layer_10/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1311 bert/encoder/layer_10/attention/self/value/BiasAdd" -> "1312 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[]", style=solid];
"1312 bert/encoder/layer_10/attention/self/Reshape_2" -> "1313 bert/encoder/layer_10/attention/self/transpose_2"  [label="[]", style=solid];
"1313 bert/encoder/layer_10/attention/self/transpose_2" -> "1335 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1314 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1315 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1315 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1316 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1316 bert/encoder/layer_10/attention/self/query/MatMul" -> "1317 bert/encoder/layer_10/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1317 bert/encoder/layer_10/attention/self/query/BiasAdd" -> "1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1320 bert/encoder/layer_10/attention/self/Reshape"  [label="[]", style=solid];
"1320 bert/encoder/layer_10/attention/self/Reshape" -> "1321 bert/encoder/layer_10/attention/self/transpose"  [label="[]", style=solid];
"1321 bert/encoder/layer_10/attention/self/transpose" -> "1331 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1322 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1323 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1323 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1324 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1324 bert/encoder/layer_10/attention/self/key/MatMul" -> "1325 bert/encoder/layer_10/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1325 bert/encoder/layer_10/attention/self/key/BiasAdd" -> "1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1328 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[]", style=solid];
"1328 bert/encoder/layer_10/attention/self/Reshape_1" -> "1329 bert/encoder/layer_10/attention/self/transpose_1"  [label="[]", style=solid];
"1329 bert/encoder/layer_10/attention/self/transpose_1" -> "1330 bert/encoder/layer_10/attention/self/MatMul__446"  [label="[]", style=solid];
"1330 bert/encoder/layer_10/attention/self/MatMul__446" -> "1331 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1331 bert/encoder/layer_10/attention/self/MatMul" -> "1332 bert/encoder/layer_10/attention/self/Mul"  [label="[]", style=solid];
"1332 bert/encoder/layer_10/attention/self/Mul" -> "1333 bert/encoder/layer_10/attention/self/add"  [label="[]", style=solid];
"1333 bert/encoder/layer_10/attention/self/add" -> "1334 bert/encoder/layer_10/attention/self/Softmax"  [label="[]", style=solid];
"1334 bert/encoder/layer_10/attention/self/Softmax" -> "1335 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1335 bert/encoder/layer_10/attention/self/MatMul_1" -> "1336 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1336 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1337 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1337 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1338 bert/encoder/layer_10/attention/self/transpose_3"  [label="[]", style=solid];
"1338 bert/encoder/layer_10/attention/self/transpose_3" -> "1339 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[]", style=solid];
"1339 bert/encoder/layer_10/attention/self/Reshape_3" -> "1342 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[]", style=solid];
"1340 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1341 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1341 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1342 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1342 bert/encoder/layer_10/attention/output/dense/MatMul" -> "1343 bert/encoder/layer_10/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1343 bert/encoder/layer_10/attention/output/dense/BiasAdd" -> "1344 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1344 bert/encoder/layer_10/attention/output/add" -> "1345 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1344 bert/encoder/layer_10/attention/output/add" -> "1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1344 bert/encoder/layer_10/attention/output/add" -> "1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1345 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1346 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1345 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1346 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" -> "1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449"  [label="[]", style=solid];
"1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" -> "1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" -> "1350 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" -> "1351 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451"  [label="[]", style=solid];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" -> "1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" -> "1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" -> "1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" -> "1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1358 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1378 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1358 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1359 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1359 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1362 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[]", style=solid];
"1360 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1361 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1361 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1362 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1362 bert/encoder/layer_10/intermediate/dense/MatMul" -> "1363 bert/encoder/layer_10/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1363 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1364 bert/encoder/layer_10/intermediate/dense/Pow"  [label="[]", style=solid];
"1363 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1366 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1363 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1371 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1364 bert/encoder/layer_10/intermediate/dense/Pow" -> "1365 bert/encoder/layer_10/intermediate/dense/mul"  [label="[]", style=solid];
"1365 bert/encoder/layer_10/intermediate/dense/mul" -> "1366 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1366 bert/encoder/layer_10/intermediate/dense/add" -> "1367 bert/encoder/layer_10/intermediate/dense/mul_1"  [label="[]", style=solid];
"1367 bert/encoder/layer_10/intermediate/dense/mul_1" -> "1368 bert/encoder/layer_10/intermediate/dense/Tanh"  [label="[]", style=solid];
"1368 bert/encoder/layer_10/intermediate/dense/Tanh" -> "1369 bert/encoder/layer_10/intermediate/dense/add_1"  [label="[]", style=solid];
"1369 bert/encoder/layer_10/intermediate/dense/add_1" -> "1370 bert/encoder/layer_10/intermediate/dense/mul_2"  [label="[]", style=solid];
"1370 bert/encoder/layer_10/intermediate/dense/mul_2" -> "1371 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1371 bert/encoder/layer_10/intermediate/dense/mul_3" -> "1372 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1372 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1373 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1373 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1376 bert/encoder/layer_10/output/dense/MatMul"  [label="[]", style=solid];
"1374 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1375 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1375 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1376 bert/encoder/layer_10/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1376 bert/encoder/layer_10/output/dense/MatMul" -> "1377 bert/encoder/layer_10/output/dense/BiasAdd"  [label="[]", style=solid];
"1377 bert/encoder/layer_10/output/dense/BiasAdd" -> "1378 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1378 bert/encoder/layer_10/output/add" -> "1379 bert/encoder/layer_10/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1378 bert/encoder/layer_10/output/add" -> "1381 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1378 bert/encoder/layer_10/output/add" -> "1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1379 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1380 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1379 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1380 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" -> "1381 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1381 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1382 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" -> "1383 bert/encoder/layer_10/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/variance" -> "1384 bert/encoder/layer_10/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1384 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" -> "1385 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1385 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" -> "1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455"  [label="[]", style=solid];
"1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" -> "1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" -> "1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" -> "1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" -> "1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1392 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1434 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1392 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1393 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1393 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1414 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[]", style=solid];
"1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1406 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[]", style=solid];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1400 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[]", style=solid];
"1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1400 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1400 bert/encoder/layer_11/attention/self/value/MatMul" -> "1401 bert/encoder/layer_11/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1401 bert/encoder/layer_11/attention/self/value/BiasAdd" -> "1402 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[]", style=solid];
"1402 bert/encoder/layer_11/attention/self/Reshape_2" -> "1403 bert/encoder/layer_11/attention/self/transpose_2"  [label="[]", style=solid];
"1403 bert/encoder/layer_11/attention/self/transpose_2" -> "1425 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1404 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1405 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1405 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1406 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1406 bert/encoder/layer_11/attention/self/query/MatMul" -> "1407 bert/encoder/layer_11/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1407 bert/encoder/layer_11/attention/self/query/BiasAdd" -> "1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1410 bert/encoder/layer_11/attention/self/Reshape"  [label="[]", style=solid];
"1410 bert/encoder/layer_11/attention/self/Reshape" -> "1411 bert/encoder/layer_11/attention/self/transpose"  [label="[]", style=solid];
"1411 bert/encoder/layer_11/attention/self/transpose" -> "1421 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1412 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1413 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1413 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1414 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1414 bert/encoder/layer_11/attention/self/key/MatMul" -> "1415 bert/encoder/layer_11/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1415 bert/encoder/layer_11/attention/self/key/BiasAdd" -> "1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1418 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[]", style=solid];
"1418 bert/encoder/layer_11/attention/self/Reshape_1" -> "1419 bert/encoder/layer_11/attention/self/transpose_1"  [label="[]", style=solid];
"1419 bert/encoder/layer_11/attention/self/transpose_1" -> "1420 bert/encoder/layer_11/attention/self/MatMul__460"  [label="[]", style=solid];
"1420 bert/encoder/layer_11/attention/self/MatMul__460" -> "1421 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1421 bert/encoder/layer_11/attention/self/MatMul" -> "1422 bert/encoder/layer_11/attention/self/Mul"  [label="[]", style=solid];
"1422 bert/encoder/layer_11/attention/self/Mul" -> "1423 bert/encoder/layer_11/attention/self/add"  [label="[]", style=solid];
"1423 bert/encoder/layer_11/attention/self/add" -> "1424 bert/encoder/layer_11/attention/self/Softmax"  [label="[]", style=solid];
"1424 bert/encoder/layer_11/attention/self/Softmax" -> "1425 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1425 bert/encoder/layer_11/attention/self/MatMul_1" -> "1426 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1426 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1427 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1427 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1428 bert/encoder/layer_11/attention/self/transpose_3"  [label="[]", style=solid];
"1428 bert/encoder/layer_11/attention/self/transpose_3" -> "1429 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[]", style=solid];
"1429 bert/encoder/layer_11/attention/self/Reshape_3" -> "1432 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[]", style=solid];
"1430 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1431 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1431 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1432 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1432 bert/encoder/layer_11/attention/output/dense/MatMul" -> "1433 bert/encoder/layer_11/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1433 bert/encoder/layer_11/attention/output/dense/BiasAdd" -> "1434 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1434 bert/encoder/layer_11/attention/output/add" -> "1435 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1434 bert/encoder/layer_11/attention/output/add" -> "1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1434 bert/encoder/layer_11/attention/output/add" -> "1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1435 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1436 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1435 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1436 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" -> "1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463"  [label="[]", style=solid];
"1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" -> "1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" -> "1440 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" -> "1441 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465"  [label="[]", style=solid];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" -> "1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" -> "1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" -> "1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" -> "1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1448 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1468 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1448 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1449 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1449 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1452 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[]", style=solid];
"1450 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1451 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1451 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1452 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1452 bert/encoder/layer_11/intermediate/dense/MatMul" -> "1453 bert/encoder/layer_11/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1453 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1454 bert/encoder/layer_11/intermediate/dense/Pow"  [label="[]", style=solid];
"1453 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1456 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1453 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1461 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1454 bert/encoder/layer_11/intermediate/dense/Pow" -> "1455 bert/encoder/layer_11/intermediate/dense/mul"  [label="[]", style=solid];
"1455 bert/encoder/layer_11/intermediate/dense/mul" -> "1456 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1456 bert/encoder/layer_11/intermediate/dense/add" -> "1457 bert/encoder/layer_11/intermediate/dense/mul_1"  [label="[]", style=solid];
"1457 bert/encoder/layer_11/intermediate/dense/mul_1" -> "1458 bert/encoder/layer_11/intermediate/dense/Tanh"  [label="[]", style=solid];
"1458 bert/encoder/layer_11/intermediate/dense/Tanh" -> "1459 bert/encoder/layer_11/intermediate/dense/add_1"  [label="[]", style=solid];
"1459 bert/encoder/layer_11/intermediate/dense/add_1" -> "1460 bert/encoder/layer_11/intermediate/dense/mul_2"  [label="[]", style=solid];
"1460 bert/encoder/layer_11/intermediate/dense/mul_2" -> "1461 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1461 bert/encoder/layer_11/intermediate/dense/mul_3" -> "1462 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1462 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1463 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1463 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1466 bert/encoder/layer_11/output/dense/MatMul"  [label="[]", style=solid];
"1464 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1465 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1465 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1466 bert/encoder/layer_11/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1466 bert/encoder/layer_11/output/dense/MatMul" -> "1467 bert/encoder/layer_11/output/dense/BiasAdd"  [label="[]", style=solid];
"1467 bert/encoder/layer_11/output/dense/BiasAdd" -> "1468 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1468 bert/encoder/layer_11/output/add" -> "1469 bert/encoder/layer_11/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1468 bert/encoder/layer_11/output/add" -> "1471 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1468 bert/encoder/layer_11/output/add" -> "1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1469 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1470 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1469 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1470 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" -> "1471 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1471 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1472 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" -> "1473 bert/encoder/layer_11/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/variance" -> "1474 bert/encoder/layer_11/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1474 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" -> "1475 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1475 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" -> "1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469"  [label="[]", style=solid];
"1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" -> "1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" -> "1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" -> "1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" -> "1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" -> "1482 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1482 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1483 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1483 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1484 bert/encoder/Reshape_13"  [label="[]", style=solid];
"1484 bert/encoder/Reshape_13" -> "1485 Shape_1"  [label="[]", style=solid];
"1484 bert/encoder/Reshape_13" -> "1497 Reshape"  [label="[]", style=solid];
"1485 Shape_1" -> "1486 Shape_1__472"  [label="[-1]", style=dashed];
"1486 Shape_1__472" -> "1487 strided_slice_1"  [label="[-1]", style=solid];
"1487 strided_slice_1" -> "1488 strided_slice_1__476"  [label="[-1]", style=solid];
"1488 strided_slice_1__476" -> "1489 strided_slice_1__477"  [label="[]", style=solid];
"1489 strided_slice_1__477" -> "1490 mul"  [label="[]", style=dashed];
"1489 strided_slice_1__477" -> "1494 Reshape_1/shape_Unsqueeze__478"  [label="[]", style=dashed];
"1490 mul" -> "1491 Reshape/shape_Unsqueeze__482"  [label="[]", style=dashed];
"1491 Reshape/shape_Unsqueeze__482" -> "1492 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"1492 Reshape/shape_Concat__484" -> "1493 Reshape__485"  [label="[2]", style=dashed];
"1493 Reshape__485" -> "1497 Reshape"  [label="[2]", style=dashed];
"1494 Reshape_1/shape_Unsqueeze__478" -> "1495 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"1495 Reshape_1/shape_Concat__481" -> "1496 Reshape_1__487"  [label="[3]", style=dashed];
"1496 Reshape_1__487" -> "1502 Reshape_1"  [label="[3]", style=dashed];
"1497 Reshape" -> "1500 MatMul"  [label="[]", style=solid];
"1498 QuantizeLinear_MatMul__486^0_1" -> "1499 DequantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=dashed];
"1499 DequantizeLinear_MatMul__486^0_1" -> "1500 MatMul"  [label="[768, 2]", style=solid];
"1500 MatMul" -> "1501 BiasAdd"  [label="[]", style=solid];
"1501 BiasAdd" -> "1502 Reshape_1"  [label="[]", style=solid];
"1502 Reshape_1" -> "1503 transpose"  [label="[]", style=solid];
"1503 transpose" -> "1504 unstack"  [label="[]", style=solid];
"1504 unstack" -> "1505 unstack__490"  [label="[]", style=solid];
"1504 unstack" -> "1507 unstack__488"  [label="[]", style=solid];
"1505 unstack__490" -> "1506 unstack_graph_outputs_Identity__4"  [label="[]", style=solid];
"1506 unstack_graph_outputs_Identity__4" -> "1513 nncf_model_output_0"  [label="[-1, 256]", style=solid];
"1507 unstack__488" -> "1508 unstack_graph_outputs_Identity__7"  [label="[]", style=solid];
"1508 unstack_graph_outputs_Identity__7" -> "1514 nncf_model_output_1"  [label="[-1, 256]", style=solid];
"1509 nncf_model_input_0" -> "0 unique_ids_graph_outputs_Identity__10"  [label="[-1]", style=dashed];
"1510 nncf_model_input_1" -> "185 bert/embeddings/Reshape_2"  [label="[-1, 256]", style=dashed];
"1511 nncf_model_input_2" -> "140 bert/encoder/Reshape"  [label="[-1, 256]", style=dashed];
"1512 nncf_model_input_3" -> "123 bert/encoder/Shape"  [label="[-1, 256]", style=dashed];
"1512 nncf_model_input_3" -> "189 bert/embeddings/ExpandDims"  [label="[-1, 256]", style=dashed];
}
